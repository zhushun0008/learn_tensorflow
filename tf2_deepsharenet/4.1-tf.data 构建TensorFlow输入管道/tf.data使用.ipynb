{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices([1,2,3,4])\n",
    "for line in ds:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensors([1,2,3,4])\n",
    "for line in ds:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2], [3, 4]])\n",
    "ds = tf.data.Dataset.from_tensors(t)   # [[1, 2], [3, 4]]\n",
    "for line in ds:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': <tf.Tensor: id=46, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>, 'b': <tf.Tensor: id=47, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>}\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2], [3, 4]])\n",
    "ds = tf.data.Dataset.from_tensors({\"a\":t,\"b\":t})   # [[1, 2], [3, 4]]\n",
    "for line in ds:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': <tf.Tensor: id=55, shape=(2,), dtype=int32, numpy=array([1, 2])>, 'b': <tf.Tensor: id=56, shape=(2,), dtype=int32, numpy=array([1, 2])>}\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2], [3, 4]])\n",
    "ds = tf.data.Dataset.from_tensor_slices({\"a\":t,\"b\":t})   # [[1, 2], [3, 4]]\n",
    "for line in ds:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset1=tf.data.Dataset.from_tensors(np.zeros(shape=(10,5,2),dtype=np.float32))\n",
    "for line in dataset1:\n",
    "    print(line.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset2=tf.data.Dataset.from_tensor_slices(np.zeros(shape=(10,5,2),dtype=np.float32))\n",
    "for line in dataset2:\n",
    "    print(line.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 2) (10, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset3=tf.data.Dataset.from_tensors({\"a\":np.zeros(shape=(10,5,2),dtype=np.float32),\"b\":np.zeros(shape=(10,5,2),dtype=np.float32)})\n",
    "for line in dataset3:\n",
    "    print(line['a'].shape,line['b'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset4 = tf.data.Dataset.from_tensor_slices({\"a\":np.zeros(shape=(10,5,2),dtype=np.float32),\"b\":np.zeros(shape=(10,5,2),dtype=np.float32)})\n",
    "for line in dataset4:\n",
    "    print(line['a'].shape,line['b'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Dataset类读取numpy数据\n",
    "最基础的建立 tf.data.Dataset 的方法是使用 tf.data.Dataset.from_tensor_slices() ，适用于数据量较小（能够整个装进内存）的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体而言，如果我们的数据集中的所有元素通过张量的第 0 维，拼接成一个大的张量（例如，前节的 MNIST 数据集的训练集即为一个 [60000, 28, 28, 1] 的张量，表示了 60000 张 28*28 的单通道灰度图像），那么我们提供一个这样的张量或者第 0 维大小相同的多个张量作为输入，即可按张量的第 0 维展开来构建数据集，数据集的元素数量为张量第 0 位的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load(\"mnist.npz\")\n",
    "\n",
    "x_train, y_train = mnist['x_train'],mnist['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in mnist_dataset:\n",
    "    plt.title(label.numpy())\n",
    "    plt.imshow(image.numpy()[:, :,0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal         object\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thal'] = pd.Categorical(df['thal'])\n",
    "df['thal'] = df.thal.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.\n",
      "   2. ], Target: 0\n",
      "Features: [ 67.    1.    4.  160.  286.    0.    2.  108.    1.    1.5   2.    3.\n",
      "   3. ], Target: 1\n",
      "Features: [ 67.    1.    4.  120.  229.    0.    2.  129.    1.    2.6   2.    2.\n",
      "   4. ], Target: 0\n",
      "Features: [ 37.    1.    3.  130.  250.    0.    0.  187.    0.    3.5   3.    0.\n",
      "   3. ], Target: 0\n",
      "Features: [ 41.    0.    2.  130.  204.    0.    2.  172.    0.    1.4   1.    0.\n",
      "   3. ], Target: 0\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "    print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从Python generator构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers = './flower_photos/flower_photos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen():\n",
    "    gen = img_gen.flow_from_directory(flowers)\n",
    "    for (x,y) in gen:\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(\n",
    "    Gen,\n",
    "    output_types=(tf.float32, tf.float32)\n",
    "#     output_shapes=([32,256,256,3], [32,5])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n",
      "(32, 256, 256, 3) (32, 5)\n"
     ]
    }
   ],
   "source": [
    "for image,label in ds:\n",
    "    print(image.shape,label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecordDataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = { # 定义Feature结构，告诉解码器每个Feature的类型是什么\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_example(example_string): # 将 TFRecord 文件中的每一个序列化的 tf.train.Example 解码\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    feature_dict['image'] = tf.io.decode_jpeg(feature_dict['image'])    # 解码JPEG图片\n",
    "    feature_dict['image'] = tf.image.resize(feature_dict['image'], [256, 256]) / 255.0\n",
    "    return feature_dict['image'], feature_dict['label']\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(\"sub_train.tfrecords\")    # 读取 TFRecord 文件\n",
    "# filename  label\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.7940257  0.64108455 0.3391238 ]\n",
      "  [0.80168504 0.64874387 0.3467831 ]\n",
      "  [0.8132659  0.66032475 0.35836396]\n",
      "  ...\n",
      "  [0.9532872  0.7964244  0.46309108]\n",
      "  [0.9428615  0.7938419  0.47619486]\n",
      "  [0.9352022  0.7861826  0.46853554]]\n",
      "\n",
      " [[0.7940257  0.64108455 0.3391238 ]\n",
      "  [0.80168504 0.64874387 0.3467831 ]\n",
      "  [0.8132659  0.66032475 0.35836396]\n",
      "  ...\n",
      "  [0.95611584 0.7992531  0.46591976]\n",
      "  [0.9428615  0.7938419  0.47619486]\n",
      "  [0.9352022  0.7861826  0.46853554]]\n",
      "\n",
      " [[0.7940257  0.64108455 0.3391238 ]\n",
      "  [0.80168504 0.64874387 0.3467831 ]\n",
      "  [0.8132659  0.66032475 0.35836396]\n",
      "  ...\n",
      "  [0.95626533 0.7985458  0.4725622 ]\n",
      "  [0.94678307 0.79776347 0.48011643]\n",
      "  [0.93912375 0.79010415 0.4724571 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.60059744 0.4790288  0.2162837 ]\n",
      "  [0.60228246 0.48071384 0.21796875]\n",
      "  [0.6060202  0.4844516  0.2217065 ]\n",
      "  ...\n",
      "  [0.00784314 0.01176471 0.        ]\n",
      "  [0.00784314 0.01176471 0.        ]\n",
      "  [0.00784314 0.01176471 0.        ]]\n",
      "\n",
      " [[0.59486824 0.47329962 0.21055454]\n",
      "  [0.5987898  0.4772212  0.21447611]\n",
      "  [0.6027114  0.48114276 0.21839768]\n",
      "  ...\n",
      "  [0.00663297 0.01055453 0.        ]\n",
      "  [0.00663297 0.01055453 0.        ]\n",
      "  [0.00663297 0.01055453 0.        ]]\n",
      "\n",
      " [[0.5891391  0.46757045 0.20482537]\n",
      "  [0.5930607  0.47149202 0.20874694]\n",
      "  [0.59698224 0.4754136  0.21266851]\n",
      "  ...\n",
      "  [0.00392157 0.00784314 0.        ]\n",
      "  [0.00392157 0.00784314 0.        ]\n",
      "  [0.00392157 0.00784314 0.        ]]], shape=(256, 256, 3), dtype=float32) tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_dataset:\n",
    "    print(image,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextLineDataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_lines = tf.data.TextLineDataset(['train.csv','eval.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_func(line):\n",
    "    line = tf.strings.split(line, sep = \",\")\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = titanic_lines.skip(1).map(data_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'0' b'male' b'22.0' b'1' b'0' b'7.25' b'Third' b'unknown' b'Southampton'\n",
      " b'n'], shape=(10,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for line in titanic_data:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
