{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = glob(\"./shuffle_data_gzip/*.csv.gz\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cv2(raw_strokes,BASE_SIZE=256, size=256, lw=6):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 255, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size)) \n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_file = \"./tfrecord_data/train.tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "    for filename in fileList[:1]:\n",
    "        df = pd.read_csv(filename)\n",
    "        df['drawing'] = df['drawing'].apply(json.loads)\n",
    "        for row in range(df.shape[0]):\n",
    "            drawing = df.loc[row,'drawing']\n",
    "            img = draw_cv2(drawing,BASE_SIZE=128, size=128, lw=6)\n",
    "            img = img.tostring()\n",
    "            label = df.loc[row,'y']\n",
    "            # 建立 tf.train.Feature 字典\n",
    "            feature = {                             \n",
    "                    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img])),  # 图片是一个 Bytes 对象\n",
    "                    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))   # 标签是一个 Int 对象\n",
    "                }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature)) # 通过字典建立 Example\n",
    "            writer.write(example.SerializeToString())   # 将Example序列化并写入 TFRecord 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 TFRecord 文件\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_file)    \n",
    "# 定义Feature结构，告诉解码器每个Feature的类型是什么\n",
    "feature_description = { \n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "# 将 TFRecord 文件中的每一个序列化的 tf.train.Example 解码\n",
    "def _parse_example(example_string): \n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    image = tf.io.decode_raw(feature_dict['image'], tf.uint8)    # 解码JPEG图片\n",
    "    image = tf.reshape(image, [128,128,1])\n",
    "    image = tf.dtypes.cast(image,tf.float32)\n",
    "    image = image / 255.0\n",
    "    label = tf.one_hot(feature_dict['label'],depth=340)\n",
    "    return image, label\n",
    "\n",
    "dataset = raw_dataset.map(_parse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE).shuffle(buffer_size=tf.data.experimental.AUTOTUNE).batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MobileNetModel(tf.keras.models.Model):\n",
    "    def __init__(self, size, n_labels, **kwargs):\n",
    "        super(MobileNetModel, self).__init__(**kwargs)\n",
    "        self.base_model = tf.keras.applications.MobileNet(input_shape=(size, size, 1), include_top=False, weights=None, classes=n_labels)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        self.outputs =  tf.keras.layers.Dense(n_labels, activation='softmax')\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.base_model(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        output_ = self.outputs(x)\n",
    "        return output_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetModel(size=128,n_labels=340)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "train_top3_accuracy = tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='train_top_3_categorical_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_top3_accuracy = tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='test_top_3_categorical_accuracy')\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train_one_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "     \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    train_top3_accuracy(labels, predictions)\n",
    "\n",
    "def val_one_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    test_top3_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0; Samples:1024; Train Loss:5.828945636749268; Train Accuracy:0.0078125\n",
      "step:200; Samples:205824; Train Loss:5.809243679046631; Train Accuracy:0.007520988583564758\n",
      "step:400; Samples:410624; Train Loss:5.806193828582764; Train Accuracy:0.007296212483197451\n",
      "step:600; Samples:615424; Train Loss:5.805119037628174; Train Accuracy:0.006967553868889809\n",
      "step:800; Samples:820224; Train Loss:5.804376125335693; Train Accuracy:0.006993211805820465\n",
      "step:1000; Samples:1025024; Train Loss:5.804078578948975; Train Accuracy:0.006914960220456123\n",
      "step:1200; Samples:1229824; Train Loss:5.803527355194092; Train Accuracy:0.006833497900515795\n",
      "step:1400; Samples:1434624; Train Loss:5.803006172180176; Train Accuracy:0.006864516530185938\n",
      "step:1600; Samples:1639424; Train Loss:5.8026323318481445; Train Accuracy:0.006941462401300669\n",
      "step:1800; Samples:1844224; Train Loss:5.802396774291992; Train Accuracy:0.00689720967784524\n",
      "Epoch 1, Loss: 5.802236557006836, Accuracy: 0.6857188940048218, Test Loss: 0.0, Test Accuracy: 0.0\n",
      "step:0; Samples:1024; Train Loss:5.7988080978393555; Train Accuracy:0.015625\n",
      "step:200; Samples:205824; Train Loss:5.801480770111084; Train Accuracy:0.007618159055709839\n",
      "step:400; Samples:410624; Train Loss:5.800490379333496; Train Accuracy:0.007578709628432989\n",
      "step:600; Samples:615424; Train Loss:5.800892353057861; Train Accuracy:0.007279533892869949\n",
      "step:800; Samples:820224; Train Loss:5.800790786743164; Train Accuracy:0.007280937861651182\n",
      "step:1000; Samples:1025024; Train Loss:5.801016330718994; Train Accuracy:0.00712178461253643\n",
      "step:1200; Samples:1229824; Train Loss:5.800800800323486; Train Accuracy:0.006953840609639883\n",
      "step:1400; Samples:1434624; Train Loss:5.800469875335693; Train Accuracy:0.0069397976621985435\n",
      "step:1600; Samples:1639424; Train Loss:5.800435543060303; Train Accuracy:0.007021978497505188\n",
      "step:1800; Samples:1844224; Train Loss:5.800412178039551; Train Accuracy:0.006990474183112383\n",
      "Epoch 2, Loss: 5.800339698791504, Accuracy: 0.6913560628890991, Test Loss: 0.0, Test Accuracy: 0.0\n",
      "step:0; Samples:1024; Train Loss:5.815678119659424; Train Accuracy:0.00390625\n",
      "step:200; Samples:205824; Train Loss:5.801100254058838; Train Accuracy:0.0076570273377001286\n",
      "step:400; Samples:410624; Train Loss:5.800053119659424; Train Accuracy:0.007617674767971039\n",
      "step:600; Samples:615424; Train Loss:5.800607681274414; Train Accuracy:0.007305532228201628\n",
      "step:800; Samples:820224; Train Loss:5.800632953643799; Train Accuracy:0.007290691137313843\n",
      "step:1000; Samples:1025024; Train Loss:5.8007121086120605; Train Accuracy:0.007090565748512745\n",
      "step:1200; Samples:1229824; Train Loss:5.800527572631836; Train Accuracy:0.006996123120188713\n",
      "step:1400; Samples:1434624; Train Loss:5.800261974334717; Train Accuracy:0.006978832185268402\n",
      "step:1600; Samples:1639424; Train Loss:5.8001790046691895; Train Accuracy:0.007053697016090155\n",
      "step:1800; Samples:1844224; Train Loss:5.800137042999268; Train Accuracy:0.007007825654000044\n",
      "Epoch 3, Loss: 5.800096035003662, Accuracy: 0.6988051533699036, Test Loss: 0.0, Test Accuracy: 0.0\n",
      "step:0; Samples:1024; Train Loss:5.819467544555664; Train Accuracy:0.01171875\n",
      "step:200; Samples:205824; Train Loss:5.800971508026123; Train Accuracy:0.007618159055709839\n",
      "step:400; Samples:410624; Train Loss:5.800253868103027; Train Accuracy:0.00758845079690218\n",
      "step:600; Samples:615424; Train Loss:5.800412654876709; Train Accuracy:0.007299032993614674\n",
      "step:800; Samples:820224; Train Loss:5.800395965576172; Train Accuracy:0.007305321283638477\n",
      "step:1000; Samples:1025024; Train Loss:5.800598621368408; Train Accuracy:0.007024225778877735\n",
      "step:1200; Samples:1229824; Train Loss:5.8003973960876465; Train Accuracy:0.006875780411064625\n",
      "step:1400; Samples:1434624; Train Loss:5.800137042999268; Train Accuracy:0.006884033791720867\n",
      "step:1600; Samples:1639424; Train Loss:5.800095081329346; Train Accuracy:0.006965861190110445\n",
      "step:1800; Samples:1844224; Train Loss:5.800061225891113; Train Accuracy:0.006931912619620562\n",
      "Epoch 4, Loss: 5.799959659576416, Accuracy: 0.6901480555534363, Test Loss: 0.0, Test Accuracy: 0.0\n",
      "step:0; Samples:1024; Train Loss:5.784605979919434; Train Accuracy:0.0078125\n",
      "step:200; Samples:205824; Train Loss:5.800832748413086; Train Accuracy:0.00767646124586463\n",
      "step:400; Samples:410624; Train Loss:5.800020694732666; Train Accuracy:0.00754948565736413\n",
      "step:600; Samples:615424; Train Loss:5.800268650054932; Train Accuracy:0.007286033593118191\n",
      "step:800; Samples:820224; Train Loss:5.800297737121582; Train Accuracy:0.007266307715326548\n",
      "step:1000; Samples:1025024; Train Loss:5.800487995147705; Train Accuracy:0.007051542401313782\n",
      "step:1200; Samples:1229824; Train Loss:5.800198078155518; Train Accuracy:0.006905053276568651\n",
      "step:1400; Samples:1434624; Train Loss:5.799978256225586; Train Accuracy:0.006892398465424776\n",
      "step:1600; Samples:1639424; Train Loss:5.799938678741455; Train Accuracy:0.006970740854740143\n",
      "step:1800; Samples:1844224; Train Loss:5.799887180328369; Train Accuracy:0.006957939825952053\n",
      "Epoch 5, Loss: 5.79980993270874, Accuracy: 0.6931679844856262, Test Loss: 0.0, Test Accuracy: 0.0\n",
      "step:0; Samples:1024; Train Loss:5.8332929611206055; Train Accuracy:0.0078125\n",
      "step:200; Samples:205824; Train Loss:5.800687313079834; Train Accuracy:0.007637593429535627\n",
      "step:400; Samples:410624; Train Loss:5.800018787384033; Train Accuracy:0.007491038180887699\n",
      "step:600; Samples:615424; Train Loss:5.800146579742432; Train Accuracy:0.007279533892869949\n",
      "step:800; Samples:820224; Train Loss:5.80014181137085; Train Accuracy:0.007285814732313156\n",
      "step:1000; Samples:1025024; Train Loss:5.8003153800964355; Train Accuracy:0.007067151367664337\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "for epoch in range(EPOCHS):\n",
    "    # 在下一个epoch开始时，重置评估指标\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_top3_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    test_top3_accuracy.reset_states()\n",
    "\n",
    "    for step,(images, labels) in enumerate(train_ds):\n",
    "        train_one_step(images, labels)\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(\"step:{0}; Samples:{1}; Train Loss:{2}; Train Accuracy:{3},Train Top3 Accuracy:{4}\".format(step, (step + 1) * 1024, \n",
    "                                                                                                             train_loss.result(), \n",
    "                                                                                                             train_accuracy.result()*100, \n",
    "                                                                                                             train_top3_accuracy.result()*100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          train_top3_accuracy()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100,\n",
    "                          test_top3_accuracy()*100\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
