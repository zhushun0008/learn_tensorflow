{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy 方式实现卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensorFlow有两种数据格式NHWC和NCHW，默认的数据格式是NHWC，可以通过参数data_format指定数据格式。\\n这个参数规定了 input Tensor 和 output Tensor 的排列方式。\\n设置为 “NHWC” 时，排列顺序为 [batch, height, width, channels]\\n设置为 “NCHW” 时，排列顺序为 [batch, channels, height, width]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "TensorFlow有两种数据格式NHWC和NCHW，默认的数据格式是NHWC，可以通过参数data_format指定数据格式。\n",
    "这个参数规定了 input Tensor 和 output Tensor 的排列方式。\n",
    "设置为 “NHWC” 时，排列顺序为 [batch, height, width, channels]\n",
    "设置为 “NCHW” 时，排列顺序为 [batch, channels, height, width]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_numpy(x, w, b, pad,strides):\n",
    "    out = None\n",
    "    \n",
    "    N, H, W, C = x.shape\n",
    "    F,  HH, WW, C = w.shape\n",
    "  \n",
    "    X = np.pad(x, ((0, 0),(pad, pad), (pad, pad), (0, 0) ), 'constant')\n",
    "\n",
    "    Hn = 1 + int((H + 2 * pad - HH) / strides[0])\n",
    "    Wn = 1 + int((W + 2 * pad - WW) / strides[1])\n",
    "    \n",
    "    out = np.zeros((N, Hn, Wn, F))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for m in range(F):\n",
    "            for i in range(Hn):\n",
    "                for j in range(Wn):\n",
    "                    data = X[n, i * strides[0]:i * strides[0] + HH, j * strides[1]:j * strides[1] + WW, :].reshape(1, -1)\n",
    "                    filt = w[m].reshape(-1, 1)\n",
    "                    out[n, i, j, m] = data.dot(filt) + b[m]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = np.random.random((10,28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random((6,3,3,3))\n",
    "b = np.random.random((6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = inputs_.astype(np.float32)\n",
    "w = w.astype(np.float32)\n",
    "b = b.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= conv_numpy(inputs_,w = w, b=b, pad=1,strides=(1,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 26, 26, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Conv2D(filters=6,kernel_size=(3,3))(inputs_).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf版本实现卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(x, w, b, pad, stride):\n",
    "    N, H, W, C = tf.shape(x)\n",
    "    F, HH, WW, C = tf.shape(w)\n",
    "\n",
    "    x = tf.pad(x, ((0, 0),(pad, pad), (pad, pad), (0, 0) ), 'constant')\n",
    "    Hn = 1 + int((H + 2 * pad - HH) / stride[0])\n",
    "    Wn = 1 + int((W + 2 * pad - WW) / stride[1])\n",
    "    Y = tf.Variable(tf.zeros((N, Hn, Wn, F),dtype=tf.float32))\n",
    "\n",
    "    for m in range(F):\n",
    "        for i in range(Hn):\n",
    "            for j in range(Wn):\n",
    "                data = x[:, i * stride[0]:i * 1 + HH, j * stride[1]:j * 1 + WW, :]\n",
    "                filt = w[m,:,:,:]\n",
    "                Y[:, i, j, m].assign(tf.reduce_sum(tf.multiply(data,filt),axis=(1,2,3))+b[m])\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(inputs_)\n",
    "w_tf = tf.constant(w)\n",
    "b_tf = tf.constant(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.dtypes.cast(x,dtype=tf.float32)\n",
    "b_tf = tf.dtypes.cast(w_tf,dtype=tf.float32)\n",
    "b_tf = tf.dtypes.cast(b_tf,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d(x,w,b,1,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self,filters=None,kernel_size=(3,3),stride=(1,1),pad = 0, **kwargs):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad = 0 \n",
    "        \n",
    "        super(Conv2D,self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                shape=(self.filters,input_shape[-1],self.kernel_size[0],self.kernel_size[1]),\n",
    "                                initializer=tf.random_normal_initializer())\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                shape=(self.filters,),\n",
    "                                initializer=tf.random_normal_initializer())\n",
    "        \n",
    "        super(Conv2D,self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.corr2d(inputs, self.w, self.b,self.pad,self.stride)\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def corr2d(x, w, b, pad, stride):\n",
    "        N, H, W, C = tf.shape(x)\n",
    "        F, HH, WW, C = tf.shape(w)\n",
    "        \n",
    "        Hn = 1 + int((H + pad - HH) / stride[0])\n",
    "        Wn = 1 + int((W + pad - WW) / stride[1])\n",
    "        Y = tf.Variable(tf.zeros((N, Hn, Wn, F),dtype=tf.float32))\n",
    "\n",
    "        for m in range(F):\n",
    "            for i in range(Hn):\n",
    "                for j in range(Wn):\n",
    "                    data = x[:, i * 1:i * 1 + HH, j * 1:j * 1 + WW, :]\n",
    "                    filt = w[m,:,:,:]\n",
    "                    Y[:, i, j, m].assign(tf.reduce_sum(tf.multiply(data,filt),axis=(1,2,3))+b[m])\n",
    "\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = Conv2D(filters=6,kernel_size=(3,3),stride=(1,1),pad = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((10,3,3,3))\n",
    "w = tf.random.uniform((6,3,3,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=388, shape=(10,), dtype=float32, numpy=\n",
       "array([5.9358387, 4.895552 , 5.4961605, 5.9548607, 4.543584 , 5.6806326,\n",
       "       5.212574 , 5.0141573, 5.491521 , 5.8198013], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.multiply(x,w),axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function multiply in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "multiply(x, y, name=None)\n",
      "    Returns x * y element-wise.\n",
      "    \n",
      "    *NOTE*: `tf.multiply` supports broadcasting. More about broadcasting\n",
      "    [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "    \n",
      "    Args:\n",
      "      x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "      y: A `Tensor`. Must have the same type as `x`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `x`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((10,28,28,3))\n",
    "w = tf.random.uniform((6,3,3,3))\n",
    "b = tf.random.uniform((6,))\n",
    "x = tf.dtypes.cast(x,tf.float32)\n",
    "N, H, W, C = tf.shape(x)\n",
    "F, HH, WW,C = tf.shape(w)\n",
    "\n",
    "\n",
    "Hn = 1 + int((H + 2 * 0 - HH) / 1)\n",
    "Wn = 1 + int((W + 2 * 0 - WW) / 1)\n",
    "Y = tf.Variable(tf.zeros((N, Hn, Wn, F)))\n",
    "\n",
    "for n in range(N):\n",
    "    for m in range(F):\n",
    "        for i in range(Hn):\n",
    "            for j in range(Wn):\n",
    "                data = x[n, i * 1:i * 1 + HH, j * 1:j * 1 + WW, :]\n",
    "                \n",
    "                print(data.shape)\n",
    "                filt = w[n]\n",
    "                print(tf.matmul(data,filt).shape)\n",
    "                Y[n, i, j, m].assign(tf.cast(tf.matmul(data,filt) ,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Conv2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d(x,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=864, shape=(1, 1), dtype=float32, numpy=array([[0.61994416]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant([[0,1,2], [3,4,5], [6,7,8]])\n",
    "K = tf.constant([[0,1], [2,3]])\n",
    "a(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_forward_naive(x, pool_size=(2,2),strides=(1,1)):\n",
    "\n",
    "    N, H, W, C = x.shape\n",
    "    h_p, w_p = pool_size\n",
    "    h_s, w_s = strides\n",
    "    \n",
    "    \n",
    "    Hn = 1 + int((H - h_p) / h_s)\n",
    "    Wn = 1 + int((W - w_p) / w_s)\n",
    "    out = np.zeros((N, Hn, Wn, C))\n",
    "    for i in range(Hn):\n",
    "        for j in range(Wn):\n",
    "            out[:, i, j, :] = np.max(x[:, i*h_s:i*h_s+h_p, j*w_s:j*w_s+w_p, :], axis=(1,2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((10,26,26,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_pool_res = max_pool_forward_naive(x,pool_size=(2,2),strides=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 25, 25, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_pool_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =tf.constant(x,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size=(2,2),strides=(1,1)):\n",
    "    N, H, W, C = tf.shape(X)\n",
    "    p_h, p_w = pool_size\n",
    "    s_h, s_w = strides\n",
    "    Y = tf.zeros((N, (H - p_h + 1)//s_h, (W - p_w +1)//s_w, C))\n",
    "    Y = tf.Variable(Y)\n",
    "\n",
    "    for i in tf.range(tf.shape(Y)[1]):\n",
    "        for j in tf.range(tf.shape(Y)[2]):\n",
    "            Y[:,i,j,:].assign(tf.math.reduce_max(X[:,i*s_h:i*s_h+p_h, j*s_w:j*s_w+p_w,:],axis=(1,2),keepdims=False))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_pool_res = pool2d(x,pool_size=(2,2),strides=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 12, 12, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_pool_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_pool_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_pool_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_2d(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
