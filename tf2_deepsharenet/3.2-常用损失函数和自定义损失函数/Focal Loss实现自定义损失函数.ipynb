{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结合focal loss 函数讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load(\"mnist.npz\")\n",
    "x_train, y_train, x_test, y_test = mnist['x_train'],mnist['y_train'],mnist['x_test'],mnist['y_test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "fig, ax = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=5,\n",
    "    sharex=True,\n",
    "    sharey=True, )\n",
    " \n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = x_train[y_train == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    \n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "y_train = tf.one_hot(y_train,depth=10)\n",
    "y_test = tf.one_hot(y_test,depth=10)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #多分类的focal loss 损失函数\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "\n",
    "#     def __init__(self,gamma=2.0,alpha=0.25):\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         super(FocalLoss, self).__init__()\n",
    "\n",
    "#     def call(self,y_true,y_pred):\n",
    "#         y_pred = tf.nn.softmax(y_pred,axis=-1)\n",
    "#         epsilon = tf.keras.backend.epsilon()#1e-7\n",
    "#         y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)\n",
    "        \n",
    "       \n",
    "#         y_true = tf.cast(y_true,tf.float32)\n",
    "        \n",
    "#         loss = -  y_true * tf.math.pow(1 - y_pred, self.gamma) * tf.math.log(y_pred)\n",
    "        \n",
    "#         loss = tf.math.reduce_sum(loss,axis=1)\n",
    "#         return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FocalLoss(gamma=2.0,alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.nn.softmax(y_pred,axis=-1)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)\n",
    "\n",
    "        y_true = tf.cast(y_true,tf.float32)\n",
    "\n",
    "        loss = -  y_true * tf.math.pow(1 - y_pred, gamma) * tf.math.log(y_pred)\n",
    "\n",
    "        loss = tf.math.reduce_sum(loss,axis=1)\n",
    "        return  loss\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MyModel()\n",
    "\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "loss_object = FocalLoss(gamma=2.0,alpha=0.25)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1, Loss: 1.0062854290008545, Accuracy: 88.1866683959961, Test Loss: 0.899224042892456, Test Accuracy: 97.05000305175781\n",
      "Epoch 2, Loss: 0.8931533098220825, Accuracy: 97.54166412353516, Test Loss: 0.8904874920845032, Test Accuracy: 97.68000030517578\n",
      "Epoch 3, Loss: 0.8832218647003174, Accuracy: 98.30166625976562, Test Loss: 0.8857290744781494, Test Accuracy: 98.02999877929688\n",
      "Epoch 4, Loss: 0.879651665687561, Accuracy: 98.54666900634766, Test Loss: 0.8816375732421875, Test Accuracy: 98.4000015258789\n",
      "Epoch 5, Loss: 0.8753460049629211, Accuracy: 98.89666748046875, Test Loss: 0.8853973746299744, Test Accuracy: 98.06999969482422\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    # 在下一个epoch开始时，重置评估指标\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
