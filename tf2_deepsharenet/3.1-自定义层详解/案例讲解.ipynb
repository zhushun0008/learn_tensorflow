{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#Dense\n",
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        self.units = units\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "\n",
    "    #build方法一般定义Layer需要被训练的参数。    \n",
    "    def build(self, input_shape): \n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name='w')\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name='b')\n",
    "        super(MyDense,self).build(input_shape) # 相当于设置self.built = True\n",
    "\n",
    "    #call方法一般定义正向传播运算逻辑，__call__方法调用了它。    \n",
    "    def call(self, inputs): \n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    #如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。\n",
    "    def get_config(self):  \n",
    "        config = super(MyDense, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# data=MinMaxScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels#(150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络   函数式构建的网络\n",
    "inputs = tf.keras.Input(shape=(4,))  \n",
    "x = MyDense(units=16)(inputs) \n",
    "x = tf.nn.tanh(x) \n",
    "x = MyDense(units=3)(x) #0,1,2\n",
    "# x= tf.keras.layers.Dense(16)(x)\n",
    "predictions = tf.nn.softmax(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data,labels.reshape(150,1)),axis=-1)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,-1]\n",
    "data = data[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels  ==[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 7ms/sample - loss: 1.0939 - sparse_categorical_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 1.0906 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0873 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0843 - sparse_categorical_accuracy: 0.6533\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 1.0810 - sparse_categorical_accuracy: 0.6267\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 1.0776 - sparse_categorical_accuracy: 0.6267\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 1.0737 - sparse_categorical_accuracy: 0.6467\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 1.0695 - sparse_categorical_accuracy: 0.6467\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 1.0648 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 1.0592 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 1.0534 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 1.0464 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0389 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 1.0305 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 213us/sample - loss: 1.0216 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 1.0115 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 206us/sample - loss: 1.0006 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.9899 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.9781 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.9662 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.9550 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.9437 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9330 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.9224 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9125 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.9038 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8950 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8872 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8804 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8738 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8679 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.8625 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.8576 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8530 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8488 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8450 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8414 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8378 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8346 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8313 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8283 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8255 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8226 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8195 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8165 - sparse_categorical_accuracy: 0.6800\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8137 - sparse_categorical_accuracy: 0.6800\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8110 - sparse_categorical_accuracy: 0.6800\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8082 - sparse_categorical_accuracy: 0.6933\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8058 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8030 - sparse_categorical_accuracy: 0.7133\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8004 - sparse_categorical_accuracy: 0.7133\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7979 - sparse_categorical_accuracy: 0.7267\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7954 - sparse_categorical_accuracy: 0.7400\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7927 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7900 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7874 - sparse_categorical_accuracy: 0.8133\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7847 - sparse_categorical_accuracy: 0.8400\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7817 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7790 - sparse_categorical_accuracy: 0.8533\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7764 - sparse_categorical_accuracy: 0.8933\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7736 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7705 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7678 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7648 - sparse_categorical_accuracy: 0.9067\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7620 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7592 - sparse_categorical_accuracy: 0.9467\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7561 - sparse_categorical_accuracy: 0.9533\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7532 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7503 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7480 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7442 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7427 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7389 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7371 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7335 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7305 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7279 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7250 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7223 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7202 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7170 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7148 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7122 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7101 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7072 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7045 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.7022 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.6997 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6977 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6959 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6930 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.6909 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6887 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6867 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.6843 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6825 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.6806 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6786 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6777 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6751 - sparse_categorical_accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28177a6a128>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#优化器 Adam\n",
    "#损失函数 交叉熵损失函数\n",
    "#评估函数 #acc\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "#keras\n",
    "model.fit(data, labels, batch_size=32, epochs=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _custom_objects = {\n",
    "#     \"Mylayer\" :  Line,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "my_dense (MyDense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Tanh (TensorFlow [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "my_dense_1 (MyDense)         (None, 3)                 51        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorF [(None, 3)]               0         \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model_tf_version.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_custom_objects = {\n",
    "    \"MyDense\" :  MyDense,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"keras_model_tf_version.h5\",custom_objects=_custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = new_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0,\n",
       "       0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 1, 1, 1, 1, 2, 1,\n",
       "       2, 2, 1, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 0, 1, 0, 1, 1, 2, 1,\n",
       "       1, 2, 2, 0, 1, 1, 0, 2, 0, 1, 0, 0, 2, 2, 1, 1, 2, 2, 1, 2, 0, 0,\n",
       "       1, 0, 2, 2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 2, 2, 1, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 0, 2, 2, 1, 1, 2,\n",
       "       1, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 0., 0., 0., 2., 1., 0., 0., 0., 2., 0., 2., 0., 0., 2., 0.,\n",
       "       0., 2., 2., 0., 0., 0., 2., 0., 0., 1., 0., 2., 0., 2., 2., 2., 1.,\n",
       "       1., 2., 2., 0., 1., 1., 1., 1., 2., 1., 2., 2., 1., 0., 2., 0., 2.,\n",
       "       1., 1., 1., 2., 2., 1., 1., 0., 0., 1., 0., 1., 1., 2., 1., 1., 2.,\n",
       "       2., 0., 1., 1., 0., 2., 0., 1., 0., 0., 2., 2., 1., 1., 2., 2., 1.,\n",
       "       2., 0., 0., 1., 0., 2., 2., 0., 2., 0., 1., 2., 1., 1., 2., 2., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 2., 2., 1., 2., 1., 0., 1.,\n",
       "       1., 0., 2., 1., 0., 0., 1., 0., 2., 2., 1., 1., 1., 1., 1., 1., 2.,\n",
       "       2., 0., 2., 2., 0., 2., 2., 2., 2., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
