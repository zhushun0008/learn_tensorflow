{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Physical GPU, 4 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 设置两个逻辑GPU模拟多GPU训练\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192),\n",
    "             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync)  # 输出设备数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#黑白图片\n",
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB图片\n",
    "# def draw_cv2(raw_strokes, size=256, lw=6):\n",
    "#     img = np.zeros((BASE_SIZE, BASE_SIZE, 3), np.uint8)\n",
    "#     for t, stroke in enumerate(raw_strokes):\n",
    "#         points_count = len(stroke[0]) - 1\n",
    "#         grad = 255//points_count\n",
    "#         for i in range(len(stroke[0]) - 1):\n",
    "#             _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), (255, 255 - min(t,10)*13, max(255 - grad*i, 20)), lw)\n",
    "#     if size != BASE_SIZE:\n",
    "#         img = cv2.resize(img, (size, size))\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, resize_height=64, resize_width=64, batch_size=512, fileList=None, size=256, lw=6):\n",
    "        self.resize_height = resize_height #图片高\n",
    "        self.resize_height = resize_height #图片宽\n",
    "        self.batch_size = batch_size #batch\n",
    "        self.fileList = fileList #文件数据\n",
    "        self.size = size #画图时图片大小\n",
    "        self.lw = lw\n",
    "\n",
    "    def __call__(self):\n",
    "        def _generator(size,lw):\n",
    "            while True:\n",
    "                for filename in self.fileList:\n",
    "                    df = pd.read_csv(filename)\n",
    "                    df['drawing'] = df['drawing'].apply(json.loads)\n",
    "                    x = np.zeros((len(df), size, size))\n",
    "                    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                        x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n",
    "                    x = x / 255.\n",
    "                    x = x.reshape((len(df), size, size, 1)).astype(np.float32)\n",
    "                    y = tf.keras.utils.to_categorical(df.y, num_classes=n_labels)\n",
    "                    for x_i,y_i in zip(x,y):\n",
    "                        yield (x_i,y_i)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(generator=_generator,\n",
    "                                                 output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "                                                 output_shapes=((self.resize_height, self.resize_height, 1), (340, )),\n",
    "                                                 args=(self.size, self.lw))\n",
    "        dataset = dataset.prefetch(buffer_size=10240)\n",
    "        dataset = dataset.shuffle(buffer_size=10240).batch(self.batch_size)\n",
    "        return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DP_DIR = './shuffle_data_gzip/'\n",
    "\n",
    "\n",
    "BASE_SIZE = 256\n",
    "n_labels = 340\n",
    "np.random.seed(seed=1987)\n",
    "size = 64\n",
    "batchsize = 1024*3   \n",
    "fileList = glob.glob(\"./shuffle_data_gzip/*.csv.gz\") \n",
    "train_fileList = fileList[:-1]\n",
    "val_fileList = fileList[-1:]\n",
    "train_ds = DataLoader(resize_height=64, resize_width=64, batch_size=batchsize, fileList=train_fileList, size=size, lw=6)()    \n",
    "val_ds = DataLoader(resize_height=64, resize_width=64, batch_size=batchsize, fileList=val_fileList, size=size, lw=6)()    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNetModel():\n",
    "    inputs = tf.keras.layers.Input(shape=(size, size, 1))\n",
    "    base_model = tf.keras.applications.MobileNet(input_shape=(size, size, 1), include_top=False, weights=None, classes=n_labels)\n",
    "    x = base_model(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    predictions = tf.keras.layers.Dense(n_labels, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "with strategy.scope():\n",
    "    model = MobileNetModel()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.002), \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.CategoricalCrossentropy(), \n",
    "                           tf.keras.metrics.CategoricalAccuracy(), \n",
    "                           tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='top_3_categorical_accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenet_1.00_64 (Model)    (None, 2, 2, 1024)        3228288   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 340)               348500    \n",
      "=================================================================\n",
      "Total params: 7,772,116\n",
      "Trainable params: 7,750,228\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16000 steps, validate for 100 steps\n",
      "Epoch 1/50\n",
      "INFO:tensorflow:batch_all_reduce: 85 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 85 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "16000/16000 [==============================] - 19915s 1s/step - loss: 1.0742 - categorical_crossentropy: 1.0742 - categorical_accuracy: 0.7323 - top_3_categorical_accuracy: 0.8786 - val_loss: 0.9225 - val_categorical_crossentropy: 0.9225 - val_categorical_accuracy: 0.7650 - val_top_3_categorical_accuracy: 0.9037\n",
      "Epoch 2/50\n",
      "13144/16000 [=======================>......] - ETA: 56:55 - loss: 0.8488 - categorical_crossentropy: 0.8488 - categorical_accuracy: 0.7825 - top_3_categorical_accuracy: 0.9133"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_top_3_categorical_accuracy', factor=0.75, patience=3, min_delta=0.001,\n",
    "                          mode='max', min_lr=1e-5, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint('model_all.h5', monitor='val_top_3_categorical_accuracy', mode='max', save_best_only=True,\n",
    "                    save_weights_only=True),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=50, verbose=1,steps_per_epoch=16000,\n",
    "    validation_data = val_ds,\n",
    "    validation_steps = 100,\n",
    "#     callbacks = callbacks\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
