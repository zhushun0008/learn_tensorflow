{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果设备未在 `tf.distribute.MirroredStrategy` 的指定列表中，它会被自动检测到。\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync)) # 输出设备数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(train_images)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 2048\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#黑白图片\n",
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, resize_height=64, resize_width=64, batch_size=512, fileList=None, size=256, lw=6):\n",
    "        self.resize_height = resize_height #图片高\n",
    "        self.resize_height = resize_height #图片宽\n",
    "        self.batch_size = batch_size #batch\n",
    "        self.fileList = fileList #文件数据\n",
    "        self.size = size #画图时图片大小\n",
    "        self.lw = lw\n",
    "\n",
    "    def __call__(self):\n",
    "        def _generator(size,lw):\n",
    "            for filename in self.fileList:\n",
    "                df = pd.read_csv(filename)\n",
    "                df['drawing'] = df['drawing'].apply(json.loads)\n",
    "                x = np.zeros((len(df), size, size))\n",
    "                for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                    x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n",
    "                x = x / 255.\n",
    "                x = x.reshape((len(df), size, size, 1)).astype(np.float32)\n",
    "                y = tf.keras.utils.to_categorical(df.y, num_classes=n_labels)\n",
    "                for x_i,y_i in zip(x,y):\n",
    "                    yield (x_i,y_i)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(generator=_generator,\n",
    "                                                 output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "                                                 output_shapes=((self.resize_height, self.resize_height, 1), (340, )),\n",
    "                                                 args=(self.size, self.lw))\n",
    "        dataset = dataset.prefetch(buffer_size=10240)\n",
    "        dataset = dataset.shuffle(buffer_size=10240).batch(self.batch_size)\n",
    "        return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DP_DIR = './shuffle_data_gzip/'\n",
    "\n",
    "\n",
    "BASE_SIZE = 256\n",
    "n_labels = 340\n",
    "np.random.seed(seed=1987)\n",
    "size = 64\n",
    "batchsize = 1024    \n",
    "fileList = glob.glob(\"./shuffle_data_gzip/*.csv.gz\") \n",
    "train_fileList = fileList[:-1]\n",
    "val_fileList = fileList[-1:]\n",
    "train_ds = DataLoader(resize_height=64, resize_width=64, batch_size=GLOBAL_BATCH_SIZE, fileList=train_fileList, size=size, lw=6)()    \n",
    "val_ds = DataLoader(resize_height=64, resize_width=64, batch_size=GLOBAL_BATCH_SIZE, fileList=val_fileList, size=size, lw=6)()    \n",
    "        \n",
    "\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_ds)\n",
    "val_dist_dataset = strategy.experimental_distribute_dataset(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VGG11NetModel(tf.keras.models.Model):\n",
    "    def __init__(self, size, n_labels, **kwargs):\n",
    "        super(VGG11NetModel, self).__init__(**kwargs)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "       \n",
    "        self.conv4 = tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.pool4 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        self.conv5 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "\n",
    "        self.conv6 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.pool6 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        self.conv7 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.conv8 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        self.pool8 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate=0.5)\n",
    "        \n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate=0.5)\n",
    "        \n",
    "        self.outputs =  tf.keras.layers.Dense(n_labels, activation='softmax')\n",
    "\n",
    "        \n",
    "    def call(self, inputs,training=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.pool6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.pool8(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x,training=training)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x,training=training)\n",
    "        output_ = self.outputs(x)\n",
    "        return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG11NetModel(size=128,n_labels=340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # 将减少设置为“无”，以便我们可以在之后进行这个减少并除以全局批量大小。\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
    "      reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "#     train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "    train_top3_accuracy = tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='train_top_3_categorical_accuracy')\n",
    "\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "    test_top3_accuracy = tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='test_top_3_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必须在`strategy.scope`下创建模型和优化器。\n",
    "with strategy.scope():\n",
    "    model = VGG11NetModel(size=128,n_labels=340)\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def train_one_step(inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images,training=True)\n",
    "            loss = compute_loss(labels, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        train_accuracy.update_state(labels, predictions)\n",
    "        train_top3_accuracy.update_state(labels, predictions)\n",
    "        return loss\n",
    "\n",
    "    def val_one_step(inputs):\n",
    "        images, labels = inputs\n",
    "        predictions = model(images,training=False)\n",
    "        t_loss = loss_object(labels, predictions)\n",
    "\n",
    "        test_loss.update_state(t_loss)\n",
    "        test_accuracy.update_state(labels, predictions)\n",
    "        test_top3_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "step:0; Samples:1024; Train Loss:5.829029083251953; Train Accuracy:0.29296875,Train Top3 Accuracy:0.6103515625\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "step:200; Samples:205824; Train Loss:4.987806797027588; Train Accuracy:5.435833930969238,Train Top3 Accuracy:11.795636177062988\n",
      "step:400; Samples:410624; Train Loss:3.9336016178131104; Train Accuracy:20.184097290039062,Train Top3 Accuracy:33.400081634521484\n",
      "step:600; Samples:615424; Train Loss:3.332469940185547; Train Accuracy:30.516237258911133,Train Top3 Accuracy:45.884952545166016\n",
      "step:800; Samples:820224; Train Loss:2.9637699127197266; Train Accuracy:37.22736358642578,Train Top3 Accuracy:53.363807678222656\n",
      "step:1000; Samples:1025024; Train Loss:2.7139973640441895; Train Accuracy:41.92692184448242,Train Top3 Accuracy:58.36565399169922\n",
      "step:1200; Samples:1229824; Train Loss:2.5331804752349854; Train Accuracy:45.40806198120117,Train Top3 Accuracy:61.95481872558594\n",
      "step:1400; Samples:1434624; Train Loss:2.3927371501922607; Train Accuracy:48.1375617980957,Train Top3 Accuracy:64.68419647216797\n",
      "step:1600; Samples:1639424; Train Loss:2.281266212463379; Train Accuracy:50.33702087402344,Train Top3 Accuracy:66.84646606445312\n",
      "step:1800; Samples:1844224; Train Loss:2.1899685859680176; Train Accuracy:52.15586471557617,Train Top3 Accuracy:68.5937728881836\n",
      "step:2000; Samples:2049024; Train Loss:2.1133604049682617; Train Accuracy:53.69406509399414,Train Top3 Accuracy:70.04917907714844\n",
      "step:2200; Samples:2253824; Train Loss:2.0484769344329834; Train Accuracy:55.007110595703125,Train Top3 Accuracy:71.27580261230469\n",
      "step:2400; Samples:2458624; Train Loss:1.992353081703186; Train Accuracy:56.144187927246094,Train Top3 Accuracy:72.3268814086914\n",
      "step:2600; Samples:2663424; Train Loss:1.9428825378417969; Train Accuracy:57.15469741821289,Train Top3 Accuracy:73.24818420410156\n",
      "step:2800; Samples:2868224; Train Loss:1.899228572845459; Train Accuracy:58.041996002197266,Train Top3 Accuracy:74.05838012695312\n",
      "step:3000; Samples:3073024; Train Loss:1.8601210117340088; Train Accuracy:58.8442268371582,Train Top3 Accuracy:74.78016662597656\n",
      "step:3200; Samples:3277824; Train Loss:1.8250547647476196; Train Accuracy:59.56553268432617,Train Top3 Accuracy:75.42575073242188\n",
      "step:3400; Samples:3482624; Train Loss:1.7932989597320557; Train Accuracy:60.22080612182617,Train Top3 Accuracy:76.00667572021484\n",
      "step:3600; Samples:3687424; Train Loss:1.7643970251083374; Train Accuracy:60.81830978393555,Train Top3 Accuracy:76.53062438964844\n",
      "step:3800; Samples:3892224; Train Loss:1.737933874130249; Train Accuracy:61.37049102783203,Train Top3 Accuracy:77.009765625\n",
      "step:4000; Samples:4097024; Train Loss:1.7134510278701782; Train Accuracy:61.87931442260742,Train Top3 Accuracy:77.45268249511719\n",
      "step:4200; Samples:4301824; Train Loss:1.6910955905914307; Train Accuracy:62.34402084350586,Train Top3 Accuracy:77.8536605834961\n",
      "step:4400; Samples:4506624; Train Loss:1.6700737476348877; Train Accuracy:62.77859878540039,Train Top3 Accuracy:78.22869110107422\n",
      "step:4600; Samples:4711424; Train Loss:1.6506259441375732; Train Accuracy:63.18640899658203,Train Top3 Accuracy:78.57618713378906\n",
      "step:4800; Samples:4916224; Train Loss:1.6324899196624756; Train Accuracy:63.56845474243164,Train Top3 Accuracy:78.89952850341797\n",
      "step:5000; Samples:5121024; Train Loss:1.6155338287353516; Train Accuracy:63.924102783203125,Train Top3 Accuracy:79.20111846923828\n",
      "step:5200; Samples:5325824; Train Loss:1.5996041297912598; Train Accuracy:64.25727081298828,Train Top3 Accuracy:79.48150634765625\n",
      "step:5400; Samples:5530624; Train Loss:1.584584355354309; Train Accuracy:64.57109069824219,Train Top3 Accuracy:79.74474334716797\n",
      "step:5600; Samples:5735424; Train Loss:1.5706762075424194; Train Accuracy:64.86600494384766,Train Top3 Accuracy:79.99024200439453\n",
      "step:5800; Samples:5940224; Train Loss:1.5573930740356445; Train Accuracy:65.14511108398438,Train Top3 Accuracy:80.2235107421875\n",
      "step:6000; Samples:6145024; Train Loss:1.5448861122131348; Train Accuracy:65.40798950195312,Train Top3 Accuracy:80.44304656982422\n",
      "step:6200; Samples:6349824; Train Loss:1.5329867601394653; Train Accuracy:65.66114807128906,Train Top3 Accuracy:80.65149688720703\n",
      "step:6400; Samples:6554624; Train Loss:1.5216786861419678; Train Accuracy:65.90028381347656,Train Top3 Accuracy:80.84961700439453\n",
      "step:6600; Samples:6759424; Train Loss:1.510861873626709; Train Accuracy:66.1266860961914,Train Top3 Accuracy:81.03795623779297\n",
      "step:6800; Samples:6964224; Train Loss:1.5006401538848877; Train Accuracy:66.34326934814453,Train Top3 Accuracy:81.21526336669922\n",
      "step:7000; Samples:7169024; Train Loss:1.490708589553833; Train Accuracy:66.55335235595703,Train Top3 Accuracy:81.38720703125\n",
      "step:7200; Samples:7373824; Train Loss:1.4812089204788208; Train Accuracy:66.75745391845703,Train Top3 Accuracy:81.5516357421875\n",
      "step:7400; Samples:7578624; Train Loss:1.472240686416626; Train Accuracy:66.94902801513672,Train Top3 Accuracy:81.70709991455078\n",
      "step:7600; Samples:7783424; Train Loss:1.4636505842208862; Train Accuracy:67.13389587402344,Train Top3 Accuracy:81.85479736328125\n",
      "step:7800; Samples:7988224; Train Loss:1.4554224014282227; Train Accuracy:67.30928039550781,Train Top3 Accuracy:81.99644470214844\n",
      "step:8000; Samples:8193024; Train Loss:1.4476203918457031; Train Accuracy:67.47564697265625,Train Top3 Accuracy:82.13150787353516\n",
      "step:8200; Samples:8397824; Train Loss:1.4401112794876099; Train Accuracy:67.6362075805664,Train Top3 Accuracy:82.26006317138672\n",
      "step:8400; Samples:8602624; Train Loss:1.4327176809310913; Train Accuracy:67.79683685302734,Train Top3 Accuracy:82.38660430908203\n",
      "step:8600; Samples:8807424; Train Loss:1.4256864786148071; Train Accuracy:67.94659423828125,Train Top3 Accuracy:82.50711822509766\n",
      "step:8800; Samples:9012224; Train Loss:1.4188337326049805; Train Accuracy:68.0937728881836,Train Top3 Accuracy:82.62435150146484\n",
      "step:9000; Samples:9217024; Train Loss:1.4124051332473755; Train Accuracy:68.23213958740234,Train Top3 Accuracy:82.7342758178711\n",
      "step:9200; Samples:9421824; Train Loss:1.406173586845398; Train Accuracy:68.36592864990234,Train Top3 Accuracy:82.84062194824219\n",
      "step:9400; Samples:9626624; Train Loss:1.4001257419586182; Train Accuracy:68.49552917480469,Train Top3 Accuracy:82.94353485107422\n",
      "step:9600; Samples:9831424; Train Loss:1.3943767547607422; Train Accuracy:68.62039947509766,Train Top3 Accuracy:83.04261779785156\n",
      "step:9800; Samples:10036224; Train Loss:1.3887759447097778; Train Accuracy:68.74039459228516,Train Top3 Accuracy:83.1380615234375\n",
      "step:10000; Samples:10241024; Train Loss:1.3833248615264893; Train Accuracy:68.85784912109375,Train Top3 Accuracy:83.23098754882812\n",
      "step:10200; Samples:10445824; Train Loss:1.378007173538208; Train Accuracy:68.97183227539062,Train Top3 Accuracy:83.32156372070312\n",
      "step:10400; Samples:10650624; Train Loss:1.3728621006011963; Train Accuracy:69.082763671875,Train Top3 Accuracy:83.40906524658203\n",
      "step:10600; Samples:10855424; Train Loss:1.3679229021072388; Train Accuracy:69.19012451171875,Train Top3 Accuracy:83.49263000488281\n",
      "step:10800; Samples:11060224; Train Loss:1.3630423545837402; Train Accuracy:69.29368591308594,Train Top3 Accuracy:83.5754165649414\n",
      "step:11000; Samples:11265024; Train Loss:1.3583241701126099; Train Accuracy:69.39624786376953,Train Top3 Accuracy:83.65497589111328\n",
      "step:11200; Samples:11469824; Train Loss:1.3537874221801758; Train Accuracy:69.4933853149414,Train Top3 Accuracy:83.73175048828125\n",
      "step:11400; Samples:11674624; Train Loss:1.3493729829788208; Train Accuracy:69.58798217773438,Train Top3 Accuracy:83.80615997314453\n",
      "step:11600; Samples:11879424; Train Loss:1.3451721668243408; Train Accuracy:69.67891693115234,Train Top3 Accuracy:83.87714385986328\n",
      "step:11800; Samples:12084224; Train Loss:1.3410274982452393; Train Accuracy:69.7694091796875,Train Top3 Accuracy:83.94741821289062\n",
      "step:12000; Samples:12289024; Train Loss:1.3369783163070679; Train Accuracy:69.85752868652344,Train Top3 Accuracy:84.01604461669922\n",
      "Epoch 1, Loss: 1.3366124629974365, Accuracy: 69.86351013183594, Top3 Accuracy:84.0206069946289, Test Loss: 0.9423803091049194, Test Accuracy: 76.88191223144531, Test Top3 Accuracy: 90.02508544921875\n",
      "step:0; Samples:1024; Train Loss:1.138430118560791; Train Accuracy:74.267578125,Train Top3 Accuracy:87.59765625\n",
      "step:200; Samples:205824; Train Loss:1.096062421798706; Train Accuracy:75.06607818603516,Train Top3 Accuracy:88.03467559814453\n",
      "step:400; Samples:410624; Train Loss:1.0951327085494995; Train Accuracy:75.07141876220703,Train Top3 Accuracy:88.05415344238281\n",
      "step:600; Samples:615424; Train Loss:1.094950556755066; Train Accuracy:75.09281921386719,Train Top3 Accuracy:88.05778503417969\n",
      "step:800; Samples:820224; Train Loss:1.0939030647277832; Train Accuracy:75.11210632324219,Train Top3 Accuracy:88.0697250366211\n",
      "step:1000; Samples:1025024; Train Loss:1.0938135385513306; Train Accuracy:75.12628936767578,Train Top3 Accuracy:88.07295989990234\n",
      "step:1200; Samples:1229824; Train Loss:1.0937964916229248; Train Accuracy:75.122314453125,Train Top3 Accuracy:88.07933044433594\n",
      "step:1400; Samples:1434624; Train Loss:1.0929782390594482; Train Accuracy:75.13568115234375,Train Top3 Accuracy:88.09382629394531\n",
      "step:1600; Samples:1639424; Train Loss:1.0920696258544922; Train Accuracy:75.15005493164062,Train Top3 Accuracy:88.11038208007812\n",
      "step:1800; Samples:1844224; Train Loss:1.0912021398544312; Train Accuracy:75.17343139648438,Train Top3 Accuracy:88.12396240234375\n",
      "step:2000; Samples:2049024; Train Loss:1.0904359817504883; Train Accuracy:75.19281768798828,Train Top3 Accuracy:88.13397216796875\n",
      "step:2200; Samples:2253824; Train Loss:1.0897791385650635; Train Accuracy:75.2088394165039,Train Top3 Accuracy:88.14573669433594\n",
      "step:2400; Samples:2458624; Train Loss:1.0890158414840698; Train Accuracy:75.22856903076172,Train Top3 Accuracy:88.15927124023438\n",
      "step:2600; Samples:2663424; Train Loss:1.088218331336975; Train Accuracy:75.24609375,Train Top3 Accuracy:88.17506408691406\n",
      "step:2800; Samples:2868224; Train Loss:1.0873825550079346; Train Accuracy:75.26510620117188,Train Top3 Accuracy:88.18836212158203\n",
      "step:3000; Samples:3073024; Train Loss:1.086516261100769; Train Accuracy:75.2831802368164,Train Top3 Accuracy:88.20156860351562\n",
      "step:3200; Samples:3277824; Train Loss:1.0857664346694946; Train Accuracy:75.30006408691406,Train Top3 Accuracy:88.21178436279297\n",
      "step:3400; Samples:3482624; Train Loss:1.0852283239364624; Train Accuracy:75.31034088134766,Train Top3 Accuracy:88.21942901611328\n",
      "step:3600; Samples:3687424; Train Loss:1.0846046209335327; Train Accuracy:75.32674407958984,Train Top3 Accuracy:88.2286376953125\n",
      "step:3800; Samples:3892224; Train Loss:1.084015130996704; Train Accuracy:75.34375,Train Top3 Accuracy:88.23715209960938\n",
      "step:4000; Samples:4097024; Train Loss:1.0832220315933228; Train Accuracy:75.3624496459961,Train Top3 Accuracy:88.24813842773438\n",
      "step:4200; Samples:4301824; Train Loss:1.0826518535614014; Train Accuracy:75.37332916259766,Train Top3 Accuracy:88.25667572021484\n",
      "step:4400; Samples:4506624; Train Loss:1.0818495750427246; Train Accuracy:75.3907699584961,Train Top3 Accuracy:88.26835632324219\n",
      "step:4600; Samples:4711424; Train Loss:1.0812515020370483; Train Accuracy:75.40455627441406,Train Top3 Accuracy:88.27728271484375\n",
      "step:4800; Samples:4916224; Train Loss:1.0805957317352295; Train Accuracy:75.41917419433594,Train Top3 Accuracy:88.28646087646484\n",
      "step:5000; Samples:5121024; Train Loss:1.0800131559371948; Train Accuracy:75.43293762207031,Train Top3 Accuracy:88.29499053955078\n",
      "step:5200; Samples:5325824; Train Loss:1.0793828964233398; Train Accuracy:75.4447250366211,Train Top3 Accuracy:88.302734375\n",
      "step:5400; Samples:5530624; Train Loss:1.078728437423706; Train Accuracy:75.4581298828125,Train Top3 Accuracy:88.31066131591797\n",
      "step:5600; Samples:5735424; Train Loss:1.0782341957092285; Train Accuracy:75.47148895263672,Train Top3 Accuracy:88.31730651855469\n",
      "step:5800; Samples:5940224; Train Loss:1.0777723789215088; Train Accuracy:75.48194885253906,Train Top3 Accuracy:88.32537841796875\n",
      "step:6000; Samples:6145024; Train Loss:1.077199101448059; Train Accuracy:75.49336242675781,Train Top3 Accuracy:88.33362579345703\n",
      "step:6200; Samples:6349824; Train Loss:1.0766240358352661; Train Accuracy:75.50625610351562,Train Top3 Accuracy:88.34246063232422\n",
      "step:6400; Samples:6554624; Train Loss:1.0761147737503052; Train Accuracy:75.51701354980469,Train Top3 Accuracy:88.34967803955078\n",
      "step:6600; Samples:6759424; Train Loss:1.0755834579467773; Train Accuracy:75.52835845947266,Train Top3 Accuracy:88.35791015625\n",
      "step:6800; Samples:6964224; Train Loss:1.0751159191131592; Train Accuracy:75.53965759277344,Train Top3 Accuracy:88.3642349243164\n",
      "step:7000; Samples:7169024; Train Loss:1.0745136737823486; Train Accuracy:75.55315399169922,Train Top3 Accuracy:88.37259674072266\n",
      "step:7200; Samples:7373824; Train Loss:1.0738574266433716; Train Accuracy:75.56884002685547,Train Top3 Accuracy:88.38252258300781\n",
      "step:7400; Samples:7578624; Train Loss:1.0733554363250732; Train Accuracy:75.57904815673828,Train Top3 Accuracy:88.39018249511719\n",
      "step:7600; Samples:7783424; Train Loss:1.0728782415390015; Train Accuracy:75.5910415649414,Train Top3 Accuracy:88.3970718383789\n",
      "step:7800; Samples:7988224; Train Loss:1.0724523067474365; Train Accuracy:75.60078430175781,Train Top3 Accuracy:88.40322875976562\n",
      "step:8000; Samples:8193024; Train Loss:1.0720548629760742; Train Accuracy:75.60879516601562,Train Top3 Accuracy:88.40882873535156\n",
      "step:8200; Samples:8397824; Train Loss:1.0716155767440796; Train Accuracy:75.61804962158203,Train Top3 Accuracy:88.41460418701172\n",
      "step:8400; Samples:8602624; Train Loss:1.0710692405700684; Train Accuracy:75.6310806274414,Train Top3 Accuracy:88.42324829101562\n",
      "step:8600; Samples:8807424; Train Loss:1.0706113576889038; Train Accuracy:75.64310455322266,Train Top3 Accuracy:88.42998504638672\n",
      "step:8800; Samples:9012224; Train Loss:1.0700747966766357; Train Accuracy:75.65470123291016,Train Top3 Accuracy:88.43806457519531\n",
      "step:9000; Samples:9217024; Train Loss:1.0697333812713623; Train Accuracy:75.66340637207031,Train Top3 Accuracy:88.44313049316406\n",
      "step:9200; Samples:9421824; Train Loss:1.0693306922912598; Train Accuracy:75.67369842529297,Train Top3 Accuracy:88.44878387451172\n",
      "step:9400; Samples:9626624; Train Loss:1.0689269304275513; Train Accuracy:75.68341827392578,Train Top3 Accuracy:88.45401763916016\n",
      "step:9600; Samples:9831424; Train Loss:1.06859290599823; Train Accuracy:75.69268035888672,Train Top3 Accuracy:88.4597396850586\n",
      "step:9800; Samples:10036224; Train Loss:1.0682249069213867; Train Accuracy:75.70121765136719,Train Top3 Accuracy:88.46485900878906\n",
      "step:10000; Samples:10241024; Train Loss:1.0678290128707886; Train Accuracy:75.7103271484375,Train Top3 Accuracy:88.47108459472656\n",
      "step:10200; Samples:10445824; Train Loss:1.0674142837524414; Train Accuracy:75.71881866455078,Train Top3 Accuracy:88.47730255126953\n",
      "step:10400; Samples:10650624; Train Loss:1.0670040845870972; Train Accuracy:75.72737884521484,Train Top3 Accuracy:88.4833984375\n",
      "step:10600; Samples:10855424; Train Loss:1.0666310787200928; Train Accuracy:75.73570251464844,Train Top3 Accuracy:88.48841857910156\n",
      "step:10800; Samples:11060224; Train Loss:1.0662155151367188; Train Accuracy:75.74491882324219,Train Top3 Accuracy:88.49461364746094\n",
      "step:11000; Samples:11265024; Train Loss:1.0657941102981567; Train Accuracy:75.75486755371094,Train Top3 Accuracy:88.5014877319336\n",
      "step:11200; Samples:11469824; Train Loss:1.0653752088546753; Train Accuracy:75.76419830322266,Train Top3 Accuracy:88.50763702392578\n",
      "step:11400; Samples:11674624; Train Loss:1.0649712085723877; Train Accuracy:75.77313232421875,Train Top3 Accuracy:88.51385498046875\n",
      "step:11600; Samples:11879424; Train Loss:1.064692735671997; Train Accuracy:75.7797622680664,Train Top3 Accuracy:88.5178451538086\n",
      "step:11800; Samples:12084224; Train Loss:1.0643310546875; Train Accuracy:75.78813171386719,Train Top3 Accuracy:88.52311706542969\n",
      "step:12000; Samples:12289024; Train Loss:1.0639967918395996; Train Accuracy:75.79660034179688,Train Top3 Accuracy:88.52818298339844\n",
      "Epoch 2, Loss: 1.0638905763626099, Accuracy: 75.7972640991211, Top3 Accuracy:88.52865600585938, Test Loss: 0.9051045775413513, Test Accuracy: 77.8005142211914, Test Top3 Accuracy: 90.57081604003906\n",
      "step:0; Samples:1024; Train Loss:1.0356760025024414; Train Accuracy:76.7333984375,Train Top3 Accuracy:89.013671875\n",
      "step:200; Samples:205824; Train Loss:1.0413336753845215; Train Accuracy:76.35844421386719,Train Top3 Accuracy:88.83111572265625\n",
      "step:400; Samples:410624; Train Loss:1.0407856702804565; Train Accuracy:76.3274917602539,Train Top3 Accuracy:88.8581771850586\n",
      "step:600; Samples:615424; Train Loss:1.0412354469299316; Train Accuracy:76.319091796875,Train Top3 Accuracy:88.84220886230469\n",
      "step:800; Samples:820224; Train Loss:1.0407052040100098; Train Accuracy:76.32786560058594,Train Top3 Accuracy:88.85005950927734\n",
      "step:1000; Samples:1025024; Train Loss:1.0408800840377808; Train Accuracy:76.32557678222656,Train Top3 Accuracy:88.843994140625\n",
      "step:1200; Samples:1229824; Train Loss:1.0416816473007202; Train Accuracy:76.31031036376953,Train Top3 Accuracy:88.83891296386719\n",
      "step:1400; Samples:1434624; Train Loss:1.0412747859954834; Train Accuracy:76.313232421875,Train Top3 Accuracy:88.84815216064453\n",
      "step:1600; Samples:1639424; Train Loss:1.0406928062438965; Train Accuracy:76.3248062133789,Train Top3 Accuracy:88.85908508300781\n",
      "step:1800; Samples:1844224; Train Loss:1.040407419204712; Train Accuracy:76.33916473388672,Train Top3 Accuracy:88.86183166503906\n",
      "step:2000; Samples:2049024; Train Loss:1.0403802394866943; Train Accuracy:76.34732818603516,Train Top3 Accuracy:88.862060546875\n",
      "step:2200; Samples:2253824; Train Loss:1.0401376485824585; Train Accuracy:76.35303497314453,Train Top3 Accuracy:88.86775207519531\n",
      "step:2400; Samples:2458624; Train Loss:1.0398290157318115; Train Accuracy:76.35735321044922,Train Top3 Accuracy:88.87259674072266\n",
      "step:2600; Samples:2663424; Train Loss:1.0395275354385376; Train Accuracy:76.36257934570312,Train Top3 Accuracy:88.88002014160156\n",
      "step:2800; Samples:2868224; Train Loss:1.0390586853027344; Train Accuracy:76.36881256103516,Train Top3 Accuracy:88.88865661621094\n",
      "step:3000; Samples:3073024; Train Loss:1.0386496782302856; Train Accuracy:76.37420654296875,Train Top3 Accuracy:88.89593505859375\n",
      "step:3200; Samples:3277824; Train Loss:1.038369059562683; Train Accuracy:76.37763977050781,Train Top3 Accuracy:88.89844512939453\n",
      "step:3400; Samples:3482624; Train Loss:1.0381138324737549; Train Accuracy:76.38384246826172,Train Top3 Accuracy:88.90396118164062\n",
      "step:3600; Samples:3687424; Train Loss:1.0379855632781982; Train Accuracy:76.38737487792969,Train Top3 Accuracy:88.90507507324219\n",
      "step:4000; Samples:4097024; Train Loss:1.037318229675293; Train Accuracy:76.40143585205078,Train Top3 Accuracy:88.91603088378906\n",
      "step:4200; Samples:4301824; Train Loss:1.0373173952102661; Train Accuracy:76.4028549194336,Train Top3 Accuracy:88.91606903076172\n",
      "step:4400; Samples:4506624; Train Loss:1.036921739578247; Train Accuracy:76.40988159179688,Train Top3 Accuracy:88.92161560058594\n",
      "step:4600; Samples:4711424; Train Loss:1.0367714166641235; Train Accuracy:76.4119644165039,Train Top3 Accuracy:88.92481994628906\n",
      "step:4800; Samples:4916224; Train Loss:1.0363528728485107; Train Accuracy:76.42141723632812,Train Top3 Accuracy:88.93061065673828\n",
      "step:5000; Samples:5121024; Train Loss:1.0360897779464722; Train Accuracy:76.42827606201172,Train Top3 Accuracy:88.93477630615234\n",
      "step:5200; Samples:5325824; Train Loss:1.0358450412750244; Train Accuracy:76.43313598632812,Train Top3 Accuracy:88.93859100341797\n",
      "step:5400; Samples:5530624; Train Loss:1.035532832145691; Train Accuracy:76.44001770019531,Train Top3 Accuracy:88.94202423095703\n",
      "step:5600; Samples:5735424; Train Loss:1.0354026556015015; Train Accuracy:76.44268035888672,Train Top3 Accuracy:88.9433364868164\n",
      "step:5800; Samples:5940224; Train Loss:1.0352083444595337; Train Accuracy:76.44696807861328,Train Top3 Accuracy:88.9455337524414\n",
      "step:6000; Samples:6145024; Train Loss:1.0350215435028076; Train Accuracy:76.451904296875,Train Top3 Accuracy:88.94992065429688\n",
      "step:6200; Samples:6349824; Train Loss:1.0348302125930786; Train Accuracy:76.45668029785156,Train Top3 Accuracy:88.95386505126953\n",
      "step:6400; Samples:6554624; Train Loss:1.0346264839172363; Train Accuracy:76.45960998535156,Train Top3 Accuracy:88.95722198486328\n",
      "step:6600; Samples:6759424; Train Loss:1.0343881845474243; Train Accuracy:76.46377563476562,Train Top3 Accuracy:88.96173095703125\n",
      "step:6800; Samples:6964224; Train Loss:1.0342506170272827; Train Accuracy:76.46613311767578,Train Top3 Accuracy:88.96344757080078\n",
      "step:7000; Samples:7169024; Train Loss:1.033875584602356; Train Accuracy:76.47533416748047,Train Top3 Accuracy:88.9688720703125\n",
      "step:7200; Samples:7373824; Train Loss:1.0335144996643066; Train Accuracy:76.48360443115234,Train Top3 Accuracy:88.97301483154297\n",
      "step:7400; Samples:7578624; Train Loss:1.0333044528961182; Train Accuracy:76.48915100097656,Train Top3 Accuracy:88.97635650634766\n",
      "step:7600; Samples:7783424; Train Loss:1.0330517292022705; Train Accuracy:76.49542999267578,Train Top3 Accuracy:88.97968292236328\n",
      "step:7800; Samples:7988224; Train Loss:1.0328500270843506; Train Accuracy:76.4991683959961,Train Top3 Accuracy:88.98253631591797\n",
      "step:8000; Samples:8193024; Train Loss:1.032739281654358; Train Accuracy:76.50096130371094,Train Top3 Accuracy:88.98394775390625\n",
      "step:8200; Samples:8397824; Train Loss:1.0325953960418701; Train Accuracy:76.50436401367188,Train Top3 Accuracy:88.98599243164062\n",
      "step:8400; Samples:8602624; Train Loss:1.0323574542999268; Train Accuracy:76.51009368896484,Train Top3 Accuracy:88.98976135253906\n",
      "step:8600; Samples:8807424; Train Loss:1.0321773290634155; Train Accuracy:76.51361846923828,Train Top3 Accuracy:88.991943359375\n",
      "step:8800; Samples:9012224; Train Loss:1.0318806171417236; Train Accuracy:76.52066802978516,Train Top3 Accuracy:88.9957275390625\n",
      "step:9000; Samples:9217024; Train Loss:1.03173828125; Train Accuracy:76.52371215820312,Train Top3 Accuracy:88.99771881103516\n",
      "step:9200; Samples:9421824; Train Loss:1.0315951108932495; Train Accuracy:76.5272445678711,Train Top3 Accuracy:89.00025939941406\n",
      "step:9400; Samples:9626624; Train Loss:1.0314345359802246; Train Accuracy:76.53157806396484,Train Top3 Accuracy:89.00233459472656\n",
      "step:9600; Samples:9831424; Train Loss:1.0312942266464233; Train Accuracy:76.5350570678711,Train Top3 Accuracy:89.00440216064453\n",
      "step:9800; Samples:10036224; Train Loss:1.0311604738235474; Train Accuracy:76.53704071044922,Train Top3 Accuracy:89.00616455078125\n",
      "step:10000; Samples:10241024; Train Loss:1.030979871749878; Train Accuracy:76.54096984863281,Train Top3 Accuracy:89.00836944580078\n",
      "step:10200; Samples:10445824; Train Loss:1.0307762622833252; Train Accuracy:76.5440673828125,Train Top3 Accuracy:89.01155090332031\n",
      "step:10400; Samples:10650624; Train Loss:1.0305464267730713; Train Accuracy:76.5486068725586,Train Top3 Accuracy:89.0145263671875\n",
      "step:10600; Samples:10855424; Train Loss:1.030360460281372; Train Accuracy:76.55305480957031,Train Top3 Accuracy:89.01643371582031\n",
      "step:10800; Samples:11060224; Train Loss:1.0301434993743896; Train Accuracy:76.556884765625,Train Top3 Accuracy:89.01954650878906\n",
      "step:11000; Samples:11265024; Train Loss:1.0299367904663086; Train Accuracy:76.56266021728516,Train Top3 Accuracy:89.02281188964844\n",
      "step:11200; Samples:11469824; Train Loss:1.029774785041809; Train Accuracy:76.56623077392578,Train Top3 Accuracy:89.02503967285156\n",
      "step:11400; Samples:11674624; Train Loss:1.0296021699905396; Train Accuracy:76.56853485107422,Train Top3 Accuracy:89.02732849121094\n",
      "step:11600; Samples:11879424; Train Loss:1.0295056104660034; Train Accuracy:76.57128143310547,Train Top3 Accuracy:89.0283203125\n",
      "step:11800; Samples:12084224; Train Loss:1.029343605041504; Train Accuracy:76.5762710571289,Train Top3 Accuracy:89.0311279296875\n",
      "step:12000; Samples:12289024; Train Loss:1.0291881561279297; Train Accuracy:76.58036804199219,Train Top3 Accuracy:89.03321838378906\n",
      "Epoch 3, Loss: 1.029107928276062, Accuracy: 76.58084869384766, Top3 Accuracy:89.03349304199219, Test Loss: 0.8958162665367126, Test Accuracy: 77.99549102783203, Test Top3 Accuracy: 90.66910552978516\n",
      "step:0; Samples:1024; Train Loss:1.0207555294036865; Train Accuracy:76.416015625,Train Top3 Accuracy:89.3798828125\n",
      "step:200; Samples:205824; Train Loss:1.0190818309783936; Train Accuracy:76.831298828125,Train Top3 Accuracy:89.14764404296875\n",
      "step:400; Samples:410624; Train Loss:1.0183876752853394; Train Accuracy:76.8146743774414,Train Top3 Accuracy:89.15650177001953\n",
      "step:600; Samples:615424; Train Loss:1.018908143043518; Train Accuracy:76.81041717529297,Train Top3 Accuracy:89.15154266357422\n",
      "step:800; Samples:820224; Train Loss:1.0180635452270508; Train Accuracy:76.83145141601562,Train Top3 Accuracy:89.16451263427734\n",
      "step:1000; Samples:1025024; Train Loss:1.0187166929244995; Train Accuracy:76.82076263427734,Train Top3 Accuracy:89.15318298339844\n",
      "step:1200; Samples:1229824; Train Loss:1.019424319267273; Train Accuracy:76.81352996826172,Train Top3 Accuracy:89.15104675292969\n",
      "step:1400; Samples:1434624; Train Loss:1.0191593170166016; Train Accuracy:76.81437683105469,Train Top3 Accuracy:89.15328979492188\n",
      "step:1600; Samples:1639424; Train Loss:1.0187288522720337; Train Accuracy:76.81829071044922,Train Top3 Accuracy:89.163818359375\n",
      "step:1800; Samples:1844224; Train Loss:1.018561840057373; Train Accuracy:76.8260269165039,Train Top3 Accuracy:89.16785430908203\n",
      "step:2000; Samples:2049024; Train Loss:1.0186054706573486; Train Accuracy:76.8278579711914,Train Top3 Accuracy:89.1666030883789\n",
      "step:2200; Samples:2253824; Train Loss:1.0184041261672974; Train Accuracy:76.82796478271484,Train Top3 Accuracy:89.1712875366211\n",
      "step:2400; Samples:2458624; Train Loss:1.0182441473007202; Train Accuracy:76.83373260498047,Train Top3 Accuracy:89.17316436767578\n",
      "step:2600; Samples:2663424; Train Loss:1.0180355310440063; Train Accuracy:76.83662414550781,Train Top3 Accuracy:89.1788101196289\n",
      "step:2800; Samples:2868224; Train Loss:1.017714500427246; Train Accuracy:76.84074401855469,Train Top3 Accuracy:89.18553161621094\n",
      "step:3000; Samples:3073024; Train Loss:1.0174589157104492; Train Accuracy:76.84563446044922,Train Top3 Accuracy:89.19190216064453\n",
      "step:3200; Samples:3277824; Train Loss:1.017270565032959; Train Accuracy:76.84818267822266,Train Top3 Accuracy:89.1945571899414\n",
      "step:3400; Samples:3482624; Train Loss:1.0170941352844238; Train Accuracy:76.85016632080078,Train Top3 Accuracy:89.19979095458984\n",
      "step:3600; Samples:3687424; Train Loss:1.0170382261276245; Train Accuracy:76.85057830810547,Train Top3 Accuracy:89.20085144042969\n",
      "step:3800; Samples:3892224; Train Loss:1.0169200897216797; Train Accuracy:76.85540008544922,Train Top3 Accuracy:89.20111846923828\n",
      "step:4000; Samples:4097024; Train Loss:1.0166761875152588; Train Accuracy:76.86077880859375,Train Top3 Accuracy:89.20709228515625\n",
      "step:4200; Samples:4301824; Train Loss:1.0165679454803467; Train Accuracy:76.86372375488281,Train Top3 Accuracy:89.21052551269531\n",
      "step:4400; Samples:4506624; Train Loss:1.016262173652649; Train Accuracy:76.86917114257812,Train Top3 Accuracy:89.21485900878906\n",
      "step:4600; Samples:4711424; Train Loss:1.016218662261963; Train Accuracy:76.87025451660156,Train Top3 Accuracy:89.21744537353516\n",
      "step:4800; Samples:4916224; Train Loss:1.016003966331482; Train Accuracy:76.87448120117188,Train Top3 Accuracy:89.22042846679688\n",
      "step:5000; Samples:5121024; Train Loss:1.015855312347412; Train Accuracy:76.88158416748047,Train Top3 Accuracy:89.22308349609375\n",
      "step:5200; Samples:5325824; Train Loss:1.0157763957977295; Train Accuracy:76.88232421875,Train Top3 Accuracy:89.2251968383789\n",
      "step:5400; Samples:5530624; Train Loss:1.0155667066574097; Train Accuracy:76.88676452636719,Train Top3 Accuracy:89.22738647460938\n",
      "step:5600; Samples:5735424; Train Loss:1.0155707597732544; Train Accuracy:76.8869400024414,Train Top3 Accuracy:89.22763061523438\n",
      "step:5800; Samples:5940224; Train Loss:1.015445351600647; Train Accuracy:76.8884506225586,Train Top3 Accuracy:89.22979736328125\n",
      "step:6000; Samples:6145024; Train Loss:1.0152618885040283; Train Accuracy:76.89073181152344,Train Top3 Accuracy:89.23207092285156\n",
      "step:6200; Samples:6349824; Train Loss:1.015134334564209; Train Accuracy:76.892333984375,Train Top3 Accuracy:89.23527526855469\n",
      "step:6400; Samples:6554624; Train Loss:1.0150549411773682; Train Accuracy:76.8943099975586,Train Top3 Accuracy:89.23701477050781\n",
      "step:6600; Samples:6759424; Train Loss:1.0149091482162476; Train Accuracy:76.8970947265625,Train Top3 Accuracy:89.23927307128906\n",
      "step:6800; Samples:6964224; Train Loss:1.0148173570632935; Train Accuracy:76.89839935302734,Train Top3 Accuracy:89.2408676147461\n",
      "step:7000; Samples:7169024; Train Loss:1.0146677494049072; Train Accuracy:76.90218353271484,Train Top3 Accuracy:89.24363708496094\n",
      "step:7200; Samples:7373824; Train Loss:1.0143983364105225; Train Accuracy:76.90919494628906,Train Top3 Accuracy:89.24757385253906\n",
      "step:7400; Samples:7578624; Train Loss:1.0142790079116821; Train Accuracy:76.91132354736328,Train Top3 Accuracy:89.2501220703125\n",
      "step:7600; Samples:7783424; Train Loss:1.0141239166259766; Train Accuracy:76.91671752929688,Train Top3 Accuracy:89.25199890136719\n",
      "step:7800; Samples:7988224; Train Loss:1.0140471458435059; Train Accuracy:76.91873168945312,Train Top3 Accuracy:89.25262451171875\n",
      "step:8000; Samples:8193024; Train Loss:1.013979196548462; Train Accuracy:76.9215316772461,Train Top3 Accuracy:89.25405883789062\n",
      "step:8200; Samples:8397824; Train Loss:1.0138897895812988; Train Accuracy:76.9231948852539,Train Top3 Accuracy:89.25506591796875\n",
      "step:8400; Samples:8602624; Train Loss:1.013626217842102; Train Accuracy:76.92798614501953,Train Top3 Accuracy:89.25910949707031\n",
      "step:8600; Samples:8807424; Train Loss:1.0135172605514526; Train Accuracy:76.93061828613281,Train Top3 Accuracy:89.25993347167969\n",
      "step:8800; Samples:9012224; Train Loss:1.013309121131897; Train Accuracy:76.9356918334961,Train Top3 Accuracy:89.26271057128906\n",
      "step:9000; Samples:9217024; Train Loss:1.0132485628128052; Train Accuracy:76.93759155273438,Train Top3 Accuracy:89.26412200927734\n",
      "step:9200; Samples:9421824; Train Loss:1.0131902694702148; Train Accuracy:76.9395523071289,Train Top3 Accuracy:89.2649917602539\n",
      "step:9400; Samples:9626624; Train Loss:1.0130703449249268; Train Accuracy:76.94245910644531,Train Top3 Accuracy:89.26627349853516\n",
      "step:9600; Samples:9831424; Train Loss:1.0130094289779663; Train Accuracy:76.94512176513672,Train Top3 Accuracy:89.26776123046875\n",
      "step:9800; Samples:10036224; Train Loss:1.0129520893096924; Train Accuracy:76.94685363769531,Train Top3 Accuracy:89.2687759399414\n",
      "step:10000; Samples:10241024; Train Loss:1.012858271598816; Train Accuracy:76.9483642578125,Train Top3 Accuracy:89.26976013183594\n",
      "step:10200; Samples:10445824; Train Loss:1.0126817226409912; Train Accuracy:76.95117950439453,Train Top3 Accuracy:89.27291107177734\n",
      "step:10400; Samples:10650624; Train Loss:1.0125292539596558; Train Accuracy:76.95309448242188,Train Top3 Accuracy:89.2746353149414\n",
      "step:10600; Samples:10855424; Train Loss:1.0123987197875977; Train Accuracy:76.95680236816406,Train Top3 Accuracy:89.27618408203125\n",
      "step:10800; Samples:11060224; Train Loss:1.012243628501892; Train Accuracy:76.95889282226562,Train Top3 Accuracy:89.2785415649414\n",
      "step:11000; Samples:11265024; Train Loss:1.0121160745620728; Train Accuracy:76.96150970458984,Train Top3 Accuracy:89.28059387207031\n",
      "step:11200; Samples:11469824; Train Loss:1.0120335817337036; Train Accuracy:76.96324157714844,Train Top3 Accuracy:89.28180694580078\n",
      "step:11400; Samples:11674624; Train Loss:1.011921763420105; Train Accuracy:76.96527099609375,Train Top3 Accuracy:89.28299713134766\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # `experimental_run_v2`将复制提供的计算并使用分布式输入运行它。\n",
    "\n",
    "    def distributed_train_step(dataset_inputs):\n",
    "        per_replica_losses = strategy.experimental_run_v2(train_one_step,\n",
    "                                                          args=(dataset_inputs,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                               axis=None)\n",
    "\n",
    "\n",
    "    def distributed_test_step(dataset_inputs):\n",
    "        return strategy.experimental_run_v2(val_one_step, args=(dataset_inputs,))\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # 训练循环\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for step,x in enumerate(train_dist_dataset):\n",
    "            total_loss += distributed_train_step(x)\n",
    "            num_batches += 1\n",
    "            \n",
    "\n",
    "            if step % 200 == 0:\n",
    "                train_loss = total_loss / num_batches\n",
    "                print(\"step:{0}; Samples:{1}; Train Loss:{2}; Train Accuracy:{3},Train Top3 Accuracy:{4}\".format(step, (step + 1) * 1024, \n",
    "                                                                                                                 train_loss, \n",
    "                                                                                                                 train_accuracy.result()*100, \n",
    "                                                                                                                 train_top3_accuracy.result()*100))\n",
    "\n",
    "\n",
    "\n",
    "        train_loss = total_loss / num_batches\n",
    "\n",
    "        # 测试循环\n",
    "        for x in val_dist_dataset:\n",
    "            distributed_test_step(x)\n",
    "\n",
    "            \n",
    "\n",
    "        template = 'Epoch {}, Loss: {}, Accuracy: {}, Top3 Accuracy:{}, Test Loss: {}, Test Accuracy: {}, Test Top3 Accuracy: {}'\n",
    "        print(template.format(epoch + 1,\n",
    "                              train_loss,\n",
    "                              train_accuracy.result() * 100,\n",
    "                              train_top3_accuracy.result() *100,\n",
    "                              test_loss.result(),\n",
    "                              test_accuracy.result() * 100,\n",
    "                              test_top3_accuracy.result()*100\n",
    "                             ))\n",
    "\n",
    "        \n",
    "        train_accuracy.reset_states()\n",
    "        train_top3_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "        test_top3_accuracy.reset_states()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG11NetModel(size=128,n_labels=340)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "train_top3_accuracy = tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='train_top_3_categorical_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_top3_accuracy = tf.keras.metrics.TopKCategoricalAccuracy(k=3,name='test_top_3_categorical_accuracy')\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train_one_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images,training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "     \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    train_top3_accuracy(labels, predictions)\n",
    "\n",
    "def val_one_step(images, labels):\n",
    "    predictions = model(images,training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    test_top3_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0; Samples:1024; Train Loss:5.828896522521973; Train Accuracy:0.0,Train Top3 Accuracy:0.29296875\n",
      "step:200; Samples:205824; Train Loss:5.5626397132873535; Train Accuracy:1.5503536462783813,Train Top3 Accuracy:4.0252838134765625\n",
      "step:400; Samples:410624; Train Loss:4.746968746185303; Train Accuracy:9.10638427734375,Train Top3 Accuracy:17.637304306030273\n",
      "step:600; Samples:615424; Train Loss:4.037374019622803; Train Accuracy:19.210983276367188,Train Top3 Accuracy:31.75095558166504\n",
      "step:800; Samples:820224; Train Loss:3.5587403774261475; Train Accuracy:26.81206512451172,Train Top3 Accuracy:41.37052917480469\n",
      "step:1000; Samples:1025024; Train Loss:3.22253155708313; Train Accuracy:32.380706787109375,Train Top3 Accuracy:48.05263137817383\n",
      "step:1200; Samples:1229824; Train Loss:2.9760067462921143; Train Accuracy:36.644996643066406,Train Top3 Accuracy:52.932125091552734\n",
      "step:1400; Samples:1434624; Train Loss:2.784346342086792; Train Accuracy:40.01933670043945,Train Top3 Accuracy:56.686771392822266\n",
      "step:1600; Samples:1639424; Train Loss:2.6311419010162354; Train Accuracy:42.765140533447266,Train Top3 Accuracy:59.65229415893555\n",
      "step:1800; Samples:1844224; Train Loss:2.5065643787384033; Train Accuracy:45.022945404052734,Train Top3 Accuracy:62.066917419433594\n",
      "step:2000; Samples:2049024; Train Loss:2.402157783508301; Train Accuracy:46.94093322753906,Train Top3 Accuracy:64.0606918334961\n",
      "step:2200; Samples:2253824; Train Loss:2.31327223777771; Train Accuracy:48.574867248535156,Train Top3 Accuracy:65.75765991210938\n",
      "step:2400; Samples:2458624; Train Loss:2.2365944385528564; Train Accuracy:49.993534088134766,Train Top3 Accuracy:67.22101593017578\n",
      "step:2600; Samples:2663424; Train Loss:2.1694576740264893; Train Accuracy:51.25331115722656,Train Top3 Accuracy:68.49480438232422\n",
      "step:2800; Samples:2868224; Train Loss:2.1094725131988525; Train Accuracy:52.386878967285156,Train Top3 Accuracy:69.61872863769531\n",
      "step:3000; Samples:3073024; Train Loss:2.056330680847168; Train Accuracy:53.383636474609375,Train Top3 Accuracy:70.61418914794922\n",
      "step:3200; Samples:3277824; Train Loss:2.0096373558044434; Train Accuracy:54.26249694824219,Train Top3 Accuracy:71.48974609375\n",
      "step:3400; Samples:3482624; Train Loss:1.9670292139053345; Train Accuracy:55.080448150634766,Train Top3 Accuracy:72.28138732910156\n",
      "step:3600; Samples:3687424; Train Loss:1.9285738468170166; Train Accuracy:55.81194305419922,Train Top3 Accuracy:72.99656677246094\n",
      "step:3800; Samples:3892224; Train Loss:1.8933014869689941; Train Accuracy:56.494895935058594,Train Top3 Accuracy:73.65218353271484\n",
      "step:4000; Samples:4097024; Train Loss:1.8611879348754883; Train Accuracy:57.112457275390625,Train Top3 Accuracy:74.24797058105469\n",
      "step:4200; Samples:4301824; Train Loss:1.8315049409866333; Train Accuracy:57.684112548828125,Train Top3 Accuracy:74.79487609863281\n",
      "step:4400; Samples:4506624; Train Loss:1.8042000532150269; Train Accuracy:58.21672821044922,Train Top3 Accuracy:75.300048828125\n",
      "step:4600; Samples:4711424; Train Loss:1.778783917427063; Train Accuracy:58.71184539794922,Train Top3 Accuracy:75.76188659667969\n",
      "step:4800; Samples:4916224; Train Loss:1.7550270557403564; Train Accuracy:59.173728942871094,Train Top3 Accuracy:76.19796752929688\n",
      "step:5000; Samples:5121024; Train Loss:1.732635498046875; Train Accuracy:59.61372375488281,Train Top3 Accuracy:76.604248046875\n",
      "step:5200; Samples:5325824; Train Loss:1.7118346691131592; Train Accuracy:60.01885986328125,Train Top3 Accuracy:76.98275756835938\n",
      "step:5400; Samples:5530624; Train Loss:1.6923075914382935; Train Accuracy:60.40142822265625,Train Top3 Accuracy:77.33487701416016\n",
      "step:5600; Samples:5735424; Train Loss:1.6736533641815186; Train Accuracy:60.7712516784668,Train Top3 Accuracy:77.67390441894531\n",
      "step:5800; Samples:5940224; Train Loss:1.6562553644180298; Train Accuracy:61.111026763916016,Train Top3 Accuracy:77.9874267578125\n",
      "step:6000; Samples:6145024; Train Loss:1.6397273540496826; Train Accuracy:61.435298919677734,Train Top3 Accuracy:78.2857666015625\n",
      "step:6200; Samples:6349824; Train Loss:1.6240062713623047; Train Accuracy:61.750465393066406,Train Top3 Accuracy:78.56771850585938\n",
      "step:6400; Samples:6554624; Train Loss:1.6091104745864868; Train Accuracy:62.04661178588867,Train Top3 Accuracy:78.83448791503906\n",
      "step:6600; Samples:6759424; Train Loss:1.5949530601501465; Train Accuracy:62.33143615722656,Train Top3 Accuracy:79.08659362792969\n",
      "step:6800; Samples:6964224; Train Loss:1.5815374851226807; Train Accuracy:62.60104751586914,Train Top3 Accuracy:79.32575225830078\n",
      "step:7000; Samples:7169024; Train Loss:1.568976640701294; Train Accuracy:62.85359191894531,Train Top3 Accuracy:79.54957580566406\n",
      "step:7200; Samples:7373824; Train Loss:1.556892991065979; Train Accuracy:63.0930290222168,Train Top3 Accuracy:79.7662353515625\n",
      "step:7400; Samples:7578624; Train Loss:1.5452290773391724; Train Accuracy:63.3277587890625,Train Top3 Accuracy:79.97309875488281\n",
      "step:7600; Samples:7783424; Train Loss:1.5340869426727295; Train Accuracy:63.5526237487793,Train Top3 Accuracy:80.17129516601562\n",
      "step:7800; Samples:7988224; Train Loss:1.5233969688415527; Train Accuracy:63.76422119140625,Train Top3 Accuracy:80.36075592041016\n",
      "step:8000; Samples:8193024; Train Loss:1.513319492340088; Train Accuracy:63.966209411621094,Train Top3 Accuracy:80.53948211669922\n",
      "step:8200; Samples:8397824; Train Loss:1.5033951997756958; Train Accuracy:64.169921875,Train Top3 Accuracy:80.71405029296875\n",
      "step:8400; Samples:8602624; Train Loss:1.4940505027770996; Train Accuracy:64.35755920410156,Train Top3 Accuracy:80.87976837158203\n",
      "step:8600; Samples:8807424; Train Loss:1.4849821329116821; Train Accuracy:64.53904724121094,Train Top3 Accuracy:81.03919219970703\n",
      "step:8800; Samples:9012224; Train Loss:1.4763776063919067; Train Accuracy:64.71187591552734,Train Top3 Accuracy:81.19141387939453\n",
      "step:9000; Samples:9217024; Train Loss:1.4678891897201538; Train Accuracy:64.88427734375,Train Top3 Accuracy:81.3410415649414\n",
      "step:9200; Samples:9421824; Train Loss:1.460072636604309; Train Accuracy:65.04426574707031,Train Top3 Accuracy:81.48029327392578\n",
      "step:9400; Samples:9626624; Train Loss:1.4525446891784668; Train Accuracy:65.19877624511719,Train Top3 Accuracy:81.61213684082031\n",
      "step:9600; Samples:9831424; Train Loss:1.444921851158142; Train Accuracy:65.35388946533203,Train Top3 Accuracy:81.74430084228516\n",
      "step:9800; Samples:10036224; Train Loss:1.4376325607299805; Train Accuracy:65.49966430664062,Train Top3 Accuracy:81.87207794189453\n",
      "step:10000; Samples:10241024; Train Loss:1.4307597875595093; Train Accuracy:65.64114379882812,Train Top3 Accuracy:81.99260711669922\n",
      "step:10200; Samples:10445824; Train Loss:1.4240168333053589; Train Accuracy:65.77871704101562,Train Top3 Accuracy:82.11042785644531\n",
      "step:10400; Samples:10650624; Train Loss:1.4173026084899902; Train Accuracy:65.91710662841797,Train Top3 Accuracy:82.22725677490234\n",
      "step:10600; Samples:10855424; Train Loss:1.4108550548553467; Train Accuracy:66.04708099365234,Train Top3 Accuracy:82.33675384521484\n",
      "step:10800; Samples:11060224; Train Loss:1.4046152830123901; Train Accuracy:66.17182922363281,Train Top3 Accuracy:82.44559478759766\n",
      "step:11000; Samples:11265024; Train Loss:1.3986448049545288; Train Accuracy:66.29277801513672,Train Top3 Accuracy:82.5493392944336\n",
      "step:11200; Samples:11469824; Train Loss:1.3928261995315552; Train Accuracy:66.41199493408203,Train Top3 Accuracy:82.65158081054688\n",
      "step:11400; Samples:11674624; Train Loss:1.3871678113937378; Train Accuracy:66.52767944335938,Train Top3 Accuracy:82.75011444091797\n",
      "step:11600; Samples:11879424; Train Loss:1.3815052509307861; Train Accuracy:66.64163970947266,Train Top3 Accuracy:82.84784698486328\n",
      "step:11800; Samples:12084224; Train Loss:1.3761075735092163; Train Accuracy:66.75074005126953,Train Top3 Accuracy:82.93914031982422\n",
      "step:12000; Samples:12289024; Train Loss:1.3709298372268677; Train Accuracy:66.85724639892578,Train Top3 Accuracy:83.02912902832031\n",
      "step:12200; Samples:12493824; Train Loss:1.3658852577209473; Train Accuracy:66.96045684814453,Train Top3 Accuracy:83.11624908447266\n",
      "step:12400; Samples:12698624; Train Loss:1.3611161708831787; Train Accuracy:67.05853271484375,Train Top3 Accuracy:83.19856262207031\n",
      "step:12600; Samples:12903424; Train Loss:1.3563470840454102; Train Accuracy:67.15672302246094,Train Top3 Accuracy:83.28063201904297\n",
      "step:12800; Samples:13108224; Train Loss:1.3516484498977661; Train Accuracy:67.25176239013672,Train Top3 Accuracy:83.36011505126953\n",
      "step:13000; Samples:13313024; Train Loss:1.3471243381500244; Train Accuracy:67.34490203857422,Train Top3 Accuracy:83.43771362304688\n",
      "step:13200; Samples:13517824; Train Loss:1.3427553176879883; Train Accuracy:67.43500518798828,Train Top3 Accuracy:83.5137939453125\n",
      "step:13400; Samples:13722624; Train Loss:1.3384943008422852; Train Accuracy:67.52135467529297,Train Top3 Accuracy:83.587890625\n",
      "step:13600; Samples:13927424; Train Loss:1.334320068359375; Train Accuracy:67.60777282714844,Train Top3 Accuracy:83.65878295898438\n",
      "step:13800; Samples:14132224; Train Loss:1.3302054405212402; Train Accuracy:67.69268798828125,Train Top3 Accuracy:83.72998046875\n",
      "step:14000; Samples:14337024; Train Loss:1.3262704610824585; Train Accuracy:67.77372741699219,Train Top3 Accuracy:83.79705810546875\n",
      "step:14200; Samples:14541824; Train Loss:1.322437047958374; Train Accuracy:67.85343933105469,Train Top3 Accuracy:83.86188507080078\n",
      "step:14400; Samples:14746624; Train Loss:1.3186899423599243; Train Accuracy:67.9308090209961,Train Top3 Accuracy:83.92605590820312\n",
      "step:14600; Samples:14951424; Train Loss:1.314955711364746; Train Accuracy:68.00806427001953,Train Top3 Accuracy:83.99010467529297\n",
      "step:14800; Samples:15156224; Train Loss:1.311272382736206; Train Accuracy:68.08561706542969,Train Top3 Accuracy:84.05262756347656\n",
      "step:15000; Samples:15361024; Train Loss:1.3077383041381836; Train Accuracy:68.15953826904297,Train Top3 Accuracy:84.1130142211914\n",
      "step:15200; Samples:15565824; Train Loss:1.3043361902236938; Train Accuracy:68.22941589355469,Train Top3 Accuracy:84.1709976196289\n",
      "step:15400; Samples:15770624; Train Loss:1.3009175062179565; Train Accuracy:68.30044555664062,Train Top3 Accuracy:84.2291030883789\n",
      "step:15600; Samples:15975424; Train Loss:1.297550916671753; Train Accuracy:68.36933135986328,Train Top3 Accuracy:84.28636932373047\n",
      "step:15800; Samples:16180224; Train Loss:1.2942615747451782; Train Accuracy:68.43775177001953,Train Top3 Accuracy:84.34149932861328\n",
      "step:16000; Samples:16385024; Train Loss:1.2910171747207642; Train Accuracy:68.5052261352539,Train Top3 Accuracy:84.39665222167969\n",
      "step:16200; Samples:16589824; Train Loss:1.2880141735076904; Train Accuracy:68.56790161132812,Train Top3 Accuracy:84.44783020019531\n",
      "step:16400; Samples:16794624; Train Loss:1.2849541902542114; Train Accuracy:68.63075256347656,Train Top3 Accuracy:84.499755859375\n",
      "step:16600; Samples:16999424; Train Loss:1.2819894552230835; Train Accuracy:68.69403076171875,Train Top3 Accuracy:84.54962158203125\n",
      "step:16800; Samples:17204224; Train Loss:1.2790861129760742; Train Accuracy:68.75387573242188,Train Top3 Accuracy:84.59911346435547\n",
      "step:17000; Samples:17409024; Train Loss:1.2761379480361938; Train Accuracy:68.8144302368164,Train Top3 Accuracy:84.64827728271484\n",
      "step:17200; Samples:17613824; Train Loss:1.2732845544815063; Train Accuracy:68.87358093261719,Train Top3 Accuracy:84.69595336914062\n",
      "step:17400; Samples:17818624; Train Loss:1.2704381942749023; Train Accuracy:68.93226623535156,Train Top3 Accuracy:84.74378967285156\n",
      "step:17600; Samples:18023424; Train Loss:1.2677818536758423; Train Accuracy:68.98794555664062,Train Top3 Accuracy:84.78890991210938\n",
      "step:17800; Samples:18228224; Train Loss:1.2651212215423584; Train Accuracy:69.04338836669922,Train Top3 Accuracy:84.8338394165039\n",
      "step:18000; Samples:18433024; Train Loss:1.262481689453125; Train Accuracy:69.09886932373047,Train Top3 Accuracy:84.87862396240234\n",
      "step:18200; Samples:18637824; Train Loss:1.259982705116272; Train Accuracy:69.15088653564453,Train Top3 Accuracy:84.9205322265625\n",
      "step:18400; Samples:18842624; Train Loss:1.2574262619018555; Train Accuracy:69.20355224609375,Train Top3 Accuracy:84.9644775390625\n",
      "step:18600; Samples:19047424; Train Loss:1.254909873008728; Train Accuracy:69.25643920898438,Train Top3 Accuracy:85.0073013305664\n",
      "step:18800; Samples:19252224; Train Loss:1.2525080442428589; Train Accuracy:69.30618286132812,Train Top3 Accuracy:85.04663848876953\n",
      "step:19000; Samples:19457024; Train Loss:1.2500993013381958; Train Accuracy:69.35707092285156,Train Top3 Accuracy:85.086669921875\n",
      "step:19200; Samples:19661824; Train Loss:1.24772310256958; Train Accuracy:69.40663146972656,Train Top3 Accuracy:85.12677764892578\n",
      "step:19400; Samples:19866624; Train Loss:1.2453529834747314; Train Accuracy:69.45650482177734,Train Top3 Accuracy:85.16674041748047\n",
      "step:19600; Samples:20071424; Train Loss:1.2430516481399536; Train Accuracy:69.50562286376953,Train Top3 Accuracy:85.20511627197266\n",
      "step:19800; Samples:20276224; Train Loss:1.2408522367477417; Train Accuracy:69.55142211914062,Train Top3 Accuracy:85.2420883178711\n",
      "step:20000; Samples:20481024; Train Loss:1.2387255430221558; Train Accuracy:69.59542083740234,Train Top3 Accuracy:85.2777099609375\n",
      "step:20200; Samples:20685824; Train Loss:1.2366561889648438; Train Accuracy:69.63878631591797,Train Top3 Accuracy:85.31217956542969\n",
      "step:20400; Samples:20890624; Train Loss:1.2345380783081055; Train Accuracy:69.68421936035156,Train Top3 Accuracy:85.34783935546875\n",
      "step:20600; Samples:21095424; Train Loss:1.2324426174163818; Train Accuracy:69.72743225097656,Train Top3 Accuracy:85.38350677490234\n",
      "step:20800; Samples:21300224; Train Loss:1.2303740978240967; Train Accuracy:69.77101135253906,Train Top3 Accuracy:85.41787719726562\n",
      "step:21000; Samples:21505024; Train Loss:1.2283235788345337; Train Accuracy:69.8134994506836,Train Top3 Accuracy:85.45210266113281\n",
      "step:21200; Samples:21709824; Train Loss:1.2263431549072266; Train Accuracy:69.85586547851562,Train Top3 Accuracy:85.48553466796875\n",
      "step:21400; Samples:21914624; Train Loss:1.2243807315826416; Train Accuracy:69.89688873291016,Train Top3 Accuracy:85.51770782470703\n",
      "step:21600; Samples:22119424; Train Loss:1.22243070602417; Train Accuracy:69.93783569335938,Train Top3 Accuracy:85.54998779296875\n",
      "step:21800; Samples:22324224; Train Loss:1.2205201387405396; Train Accuracy:69.97830963134766,Train Top3 Accuracy:85.58160400390625\n",
      "step:22000; Samples:22529024; Train Loss:1.2187857627868652; Train Accuracy:70.01486206054688,Train Top3 Accuracy:85.6109848022461\n",
      "step:22200; Samples:22733824; Train Loss:1.2169914245605469; Train Accuracy:70.05306243896484,Train Top3 Accuracy:85.64030456542969\n",
      "step:22400; Samples:22938624; Train Loss:1.2151503562927246; Train Accuracy:70.09197235107422,Train Top3 Accuracy:85.67110443115234\n",
      "step:22600; Samples:23143424; Train Loss:1.2134671211242676; Train Accuracy:70.12751770019531,Train Top3 Accuracy:85.69879150390625\n",
      "step:22800; Samples:23348224; Train Loss:1.2117198705673218; Train Accuracy:70.16499328613281,Train Top3 Accuracy:85.727294921875\n",
      "step:23000; Samples:23553024; Train Loss:1.2099816799163818; Train Accuracy:70.20171356201172,Train Top3 Accuracy:85.7558822631836\n",
      "step:23200; Samples:23757824; Train Loss:1.2082526683807373; Train Accuracy:70.238525390625,Train Top3 Accuracy:85.78514099121094\n",
      "step:23400; Samples:23962624; Train Loss:1.2065590620040894; Train Accuracy:70.27340698242188,Train Top3 Accuracy:85.81275177001953\n",
      "step:23600; Samples:24167424; Train Loss:1.2049397230148315; Train Accuracy:70.30770111083984,Train Top3 Accuracy:85.83985900878906\n",
      "step:23800; Samples:24372224; Train Loss:1.2032963037490845; Train Accuracy:70.34253692626953,Train Top3 Accuracy:85.86750030517578\n",
      "step:24000; Samples:24577024; Train Loss:1.2017509937286377; Train Accuracy:70.37452697753906,Train Top3 Accuracy:85.8938980102539\n",
      "step:24200; Samples:24781824; Train Loss:1.2001934051513672; Train Accuracy:70.408203125,Train Top3 Accuracy:85.91996765136719\n",
      "step:24400; Samples:24986624; Train Loss:1.1986308097839355; Train Accuracy:70.4408950805664,Train Top3 Accuracy:85.945556640625\n",
      "step:24600; Samples:25191424; Train Loss:1.1971782445907593; Train Accuracy:70.47115325927734,Train Top3 Accuracy:85.9703140258789\n",
      "step:24800; Samples:25396224; Train Loss:1.1956526041030884; Train Accuracy:70.50300598144531,Train Top3 Accuracy:85.99492645263672\n",
      "step:25000; Samples:25601024; Train Loss:1.1941670179367065; Train Accuracy:70.5345687866211,Train Top3 Accuracy:86.0190200805664\n",
      "step:25200; Samples:25805824; Train Loss:1.1927011013031006; Train Accuracy:70.56529235839844,Train Top3 Accuracy:86.04386138916016\n",
      "step:25400; Samples:26010624; Train Loss:1.1912707090377808; Train Accuracy:70.59551239013672,Train Top3 Accuracy:86.0671157836914\n",
      "step:25600; Samples:26215424; Train Loss:1.1898072957992554; Train Accuracy:70.6259994506836,Train Top3 Accuracy:86.0914077758789\n",
      "step:25800; Samples:26420224; Train Loss:1.1883984804153442; Train Accuracy:70.65591430664062,Train Top3 Accuracy:86.11500549316406\n",
      "step:26000; Samples:26625024; Train Loss:1.1870317459106445; Train Accuracy:70.68453979492188,Train Top3 Accuracy:86.13810729980469\n",
      "step:26200; Samples:26829824; Train Loss:1.1856143474578857; Train Accuracy:70.713623046875,Train Top3 Accuracy:86.16082763671875\n",
      "step:26400; Samples:27034624; Train Loss:1.1842806339263916; Train Accuracy:70.74205780029297,Train Top3 Accuracy:86.18317413330078\n",
      "step:26600; Samples:27239424; Train Loss:1.1829646825790405; Train Accuracy:70.77061462402344,Train Top3 Accuracy:86.20478820800781\n",
      "step:26800; Samples:27444224; Train Loss:1.1816555261611938; Train Accuracy:70.79823303222656,Train Top3 Accuracy:86.22640228271484\n",
      "step:27000; Samples:27649024; Train Loss:1.1803481578826904; Train Accuracy:70.82573699951172,Train Top3 Accuracy:86.24798583984375\n",
      "step:27200; Samples:27853824; Train Loss:1.1790555715560913; Train Accuracy:70.85243225097656,Train Top3 Accuracy:86.26940155029297\n",
      "step:27400; Samples:28058624; Train Loss:1.1777596473693848; Train Accuracy:70.8800277709961,Train Top3 Accuracy:86.29086303710938\n",
      "step:27600; Samples:28263424; Train Loss:1.1764490604400635; Train Accuracy:70.90857696533203,Train Top3 Accuracy:86.31209564208984\n",
      "step:27800; Samples:28468224; Train Loss:1.175182580947876; Train Accuracy:70.93558502197266,Train Top3 Accuracy:86.33306884765625\n",
      "step:28000; Samples:28673024; Train Loss:1.1739717721939087; Train Accuracy:70.96119689941406,Train Top3 Accuracy:86.35274505615234\n",
      "step:28200; Samples:28877824; Train Loss:1.172711730003357; Train Accuracy:70.98844909667969,Train Top3 Accuracy:86.37350463867188\n",
      "step:28400; Samples:29082624; Train Loss:1.1714876890182495; Train Accuracy:71.01512145996094,Train Top3 Accuracy:86.39306640625\n",
      "step:28600; Samples:29287424; Train Loss:1.1702393293380737; Train Accuracy:71.041015625,Train Top3 Accuracy:86.41310119628906\n",
      "step:28800; Samples:29492224; Train Loss:1.1690539121627808; Train Accuracy:71.06658172607422,Train Top3 Accuracy:86.432373046875\n",
      "step:29000; Samples:29697024; Train Loss:1.1678999662399292; Train Accuracy:71.09089660644531,Train Top3 Accuracy:86.45206451416016\n",
      "step:29200; Samples:29901824; Train Loss:1.166748046875; Train Accuracy:71.11520385742188,Train Top3 Accuracy:86.47064208984375\n",
      "step:29400; Samples:30106624; Train Loss:1.1656310558319092; Train Accuracy:71.13944244384766,Train Top3 Accuracy:86.48882293701172\n",
      "step:29600; Samples:30311424; Train Loss:1.164475679397583; Train Accuracy:71.16411590576172,Train Top3 Accuracy:86.50802612304688\n",
      "step:29800; Samples:30516224; Train Loss:1.1633683443069458; Train Accuracy:71.18790435791016,Train Top3 Accuracy:86.52641296386719\n",
      "step:30000; Samples:30721024; Train Loss:1.1622766256332397; Train Accuracy:71.21111297607422,Train Top3 Accuracy:86.54402160644531\n",
      "step:30200; Samples:30925824; Train Loss:1.1611722707748413; Train Accuracy:71.23420715332031,Train Top3 Accuracy:86.56242370605469\n",
      "step:30400; Samples:31130624; Train Loss:1.16011643409729; Train Accuracy:71.2572021484375,Train Top3 Accuracy:86.57991027832031\n",
      "step:30600; Samples:31335424; Train Loss:1.1590584516525269; Train Accuracy:71.27918243408203,Train Top3 Accuracy:86.59735107421875\n",
      "step:30800; Samples:31540224; Train Loss:1.158021092414856; Train Accuracy:71.30024719238281,Train Top3 Accuracy:86.61405944824219\n",
      "step:31000; Samples:31745024; Train Loss:1.1570383310317993; Train Accuracy:71.32183837890625,Train Top3 Accuracy:86.63008880615234\n",
      "step:31200; Samples:31949824; Train Loss:1.1560031175613403; Train Accuracy:71.34436798095703,Train Top3 Accuracy:86.64643096923828\n",
      "step:31400; Samples:32154624; Train Loss:1.1550183296203613; Train Accuracy:71.36587524414062,Train Top3 Accuracy:86.66244506835938\n",
      "step:31600; Samples:32359424; Train Loss:1.154037594795227; Train Accuracy:71.3864974975586,Train Top3 Accuracy:86.6788101196289\n",
      "step:31800; Samples:32564224; Train Loss:1.1530793905258179; Train Accuracy:71.40667724609375,Train Top3 Accuracy:86.69458770751953\n",
      "step:32000; Samples:32769024; Train Loss:1.1521204710006714; Train Accuracy:71.42741394042969,Train Top3 Accuracy:86.71048736572266\n",
      "step:32200; Samples:32973824; Train Loss:1.1511645317077637; Train Accuracy:71.44731903076172,Train Top3 Accuracy:86.72651672363281\n",
      "step:32400; Samples:33178624; Train Loss:1.150212049484253; Train Accuracy:71.4678955078125,Train Top3 Accuracy:86.74237823486328\n",
      "step:32600; Samples:33383424; Train Loss:1.1492891311645508; Train Accuracy:71.48800659179688,Train Top3 Accuracy:86.75773620605469\n",
      "step:32800; Samples:33588224; Train Loss:1.1483824253082275; Train Accuracy:71.50719451904297,Train Top3 Accuracy:86.77244567871094\n",
      "step:33000; Samples:33793024; Train Loss:1.1474545001983643; Train Accuracy:71.5273666381836,Train Top3 Accuracy:86.78756713867188\n",
      "step:33200; Samples:33997824; Train Loss:1.1464955806732178; Train Accuracy:71.5471420288086,Train Top3 Accuracy:86.80303955078125\n",
      "step:33400; Samples:34202624; Train Loss:1.14559805393219; Train Accuracy:71.56651306152344,Train Top3 Accuracy:86.8178939819336\n",
      "step:33600; Samples:34407424; Train Loss:1.144649863243103; Train Accuracy:71.58719635009766,Train Top3 Accuracy:86.83333587646484\n",
      "step:33800; Samples:34612224; Train Loss:1.1437456607818604; Train Accuracy:71.60628509521484,Train Top3 Accuracy:86.84803009033203\n",
      "step:34000; Samples:34817024; Train Loss:1.1428725719451904; Train Accuracy:71.62464904785156,Train Top3 Accuracy:86.86176300048828\n",
      "step:34200; Samples:35021824; Train Loss:1.1420235633850098; Train Accuracy:71.64302062988281,Train Top3 Accuracy:86.87565612792969\n",
      "step:34400; Samples:35226624; Train Loss:1.1411648988723755; Train Accuracy:71.6612548828125,Train Top3 Accuracy:86.88957977294922\n",
      "step:34600; Samples:35431424; Train Loss:1.1402685642242432; Train Accuracy:71.68132019042969,Train Top3 Accuracy:86.9043197631836\n",
      "step:34800; Samples:35636224; Train Loss:1.1394028663635254; Train Accuracy:71.69963836669922,Train Top3 Accuracy:86.9181900024414\n",
      "step:35000; Samples:35841024; Train Loss:1.1385304927825928; Train Accuracy:71.71784210205078,Train Top3 Accuracy:86.93209838867188\n",
      "step:35200; Samples:36045824; Train Loss:1.1376831531524658; Train Accuracy:71.73705291748047,Train Top3 Accuracy:86.94583892822266\n",
      "step:35400; Samples:36250624; Train Loss:1.136844277381897; Train Accuracy:71.75520324707031,Train Top3 Accuracy:86.95947265625\n",
      "step:35600; Samples:36455424; Train Loss:1.136035680770874; Train Accuracy:71.77252960205078,Train Top3 Accuracy:86.97235870361328\n",
      "step:35800; Samples:36660224; Train Loss:1.135239601135254; Train Accuracy:71.78970336914062,Train Top3 Accuracy:86.98555755615234\n",
      "step:36000; Samples:36865024; Train Loss:1.134461760520935; Train Accuracy:71.80620574951172,Train Top3 Accuracy:86.9981460571289\n",
      "step:36200; Samples:37069824; Train Loss:1.1336874961853027; Train Accuracy:71.82245635986328,Train Top3 Accuracy:87.01116180419922\n",
      "step:36400; Samples:37274624; Train Loss:1.1328957080841064; Train Accuracy:71.83938598632812,Train Top3 Accuracy:87.02442932128906\n",
      "step:36600; Samples:37479424; Train Loss:1.1321486234664917; Train Accuracy:71.85550689697266,Train Top3 Accuracy:87.03629302978516\n",
      "step:36800; Samples:37684224; Train Loss:1.1313726902008057; Train Accuracy:71.87223052978516,Train Top3 Accuracy:87.04895782470703\n",
      "step:37000; Samples:37889024; Train Loss:1.1306266784667969; Train Accuracy:71.88804626464844,Train Top3 Accuracy:87.06095123291016\n",
      "step:37200; Samples:38093824; Train Loss:1.129876971244812; Train Accuracy:71.90469360351562,Train Top3 Accuracy:87.07291412353516\n",
      "step:37400; Samples:38298624; Train Loss:1.1291460990905762; Train Accuracy:71.92073822021484,Train Top3 Accuracy:87.08453369140625\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "for epoch in range(EPOCHS):\n",
    "    # 在下一个epoch开始时，重置评估指标\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_top3_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    test_top3_accuracy.reset_states()\n",
    "\n",
    "    for step,(images, labels) in enumerate(train_ds):\n",
    "        train_one_step(images, labels)\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(\"step:{0}; Samples:{1}; Train Loss:{2}; Train Accuracy:{3},Train Top3 Accuracy:{4}\".format(step, (step + 1) * 1024, \n",
    "                                                                                                             train_loss.result(), \n",
    "                                                                                                             train_accuracy.result()*100, \n",
    "                                                                                                             train_top3_accuracy.result()*100))\n",
    "\n",
    "    for step,(val_images, val_labels) in enumerate(val_ds):\n",
    "        val_one_step(val_images, val_labels)\n",
    "\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          train_top3_accuracy()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100,\n",
    "                          test_top3_accuracy()*100\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
